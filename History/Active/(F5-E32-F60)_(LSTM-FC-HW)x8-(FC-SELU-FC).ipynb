{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb18dba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:34.441284Z",
     "iopub.status.busy": "2021-10-30T16:13:34.440286Z",
     "iopub.status.idle": "2021-10-30T16:13:36.209240Z",
     "shell.execute_reply": "2021-10-30T16:13:36.209240Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import argparse\n",
    "from fastai.layers import swish\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "from fastai.callback.schedule import Learner\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.losses import L1LossFlat\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.callback.tracker import ReduceLROnPlateau, SaveModelCallback\n",
    "\n",
    "from HW_base import evaluate_build, focus_build\n",
    "from HW_torch import dataLoads_build, net_parameter_count, hw_layer\n",
    "from HW_torch import torch_valid, torch_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be584b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:36.211234Z",
     "iopub.status.busy": "2021-10-30T16:13:36.211234Z",
     "iopub.status.idle": "2021-10-30T16:13:36.225215Z",
     "shell.execute_reply": "2021-10-30T16:13:36.225215Z"
    }
   },
   "outputs": [],
   "source": [
    "fname               = '(F5-E32-F60)_RES(LSTM-FC-HW)x8-(FC-SELU-FC)'\n",
    "evaluate_num        = 32\n",
    "focus_min           = 0.6\n",
    "net_block_num       = 32\n",
    "hw_active           = True\n",
    "epoch_num_first     = 100\n",
    "batch_size_first    = 100\n",
    "epoch_num_second    = 200\n",
    "batch_size_second   = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d55110b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:36.231199Z",
     "iopub.status.busy": "2021-10-30T16:13:36.230201Z",
     "iopub.status.idle": "2021-10-30T16:13:36.241180Z",
     "shell.execute_reply": "2021-10-30T16:13:36.241180Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net_block(torch.nn.Module):\n",
    "    def __init__(self, input_dims, internal_dims, output_dims, bias=True, bidirectional=True, batch_first=True, **kwargs):\n",
    "        super(Net_block, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dims, internal_dims, num_layers=1, bias=True, bidirectional=True, batch_first=True)\n",
    "        if bidirectional:\n",
    "            self.fc =nn.Linear(internal_dims*2, output_dims)\n",
    "        else:\n",
    "            self.fc =nn.Linear(internal_dims, output_dims)\n",
    "        self._reinitialize()\n",
    "        \n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        https://www.kaggle.com/junkoda/pytorch-lstm-with-tensorflow-like-initialization/notebook\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'lstm' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "            elif 'fc' in name:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'bias' in name:\n",
    "                    p.data.fill_(0)\n",
    "    \n",
    "    def forward(self, x, hw=None):\n",
    "        y, _ = self.lstm(x)\n",
    "        y = self.fc(y) + x\n",
    "        if hw is not None:\n",
    "            y = y * hw\n",
    "        return y\n",
    "        \n",
    "class Net_test(torch.nn.Module):\n",
    "    def __init__(self, evaluate_dic_list, net_block_num=net_block_num, hw_active=hw_active, **kwargs):\n",
    "        super(Net_test, self).__init__()\n",
    "        self.hw_layer = hw_layer(evaluate_dic_list)\n",
    "        self.hw_dims = self.hw_layer.channels\n",
    "        \n",
    "        self.net_block_list = nn.ModuleList()\n",
    "        for _ in range(net_block_num):\n",
    "            self.net_block_list.append(Net_block(self.hw_dims, self.hw_dims, self.hw_dims))\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(self.hw_dims, 32, bias=False),\n",
    "                                nn.SELU(),\n",
    "                                nn.Linear(32, 1, bias=True))\n",
    "        self._reinitialize()\n",
    "        \n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        https://www.kaggle.com/junkoda/pytorch-lstm-with-tensorflow-like-initialization/notebook\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'lstm' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "            elif 'fc' in name:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'bias' in name:\n",
    "                    p.data.fill_(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hw = self.hw_layer(x)\n",
    "        x = hw\n",
    "        \n",
    "        for net_block in self.net_block_list:\n",
    "            x = net_block(x, hw)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b48cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:36.243175Z",
     "iopub.status.busy": "2021-10-30T16:13:36.243175Z",
     "iopub.status.idle": "2021-10-30T16:13:40.477893Z",
     "shell.execute_reply": "2021-10-30T16:13:40.477893Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train_df = pd.read_csv('./Database/train.csv')\n",
    "data_test_df = pd.read_csv('./Database/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f896618a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.479887Z",
     "iopub.status.busy": "2021-10-30T16:13:40.479887Z",
     "iopub.status.idle": "2021-10-30T16:13:40.492874Z",
     "shell.execute_reply": "2021-10-30T16:13:40.493873Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_columns = ['pressure','id', 'breath_id','one','count','breath_id_lag','breath_id_lag2','breath_id_lagsame','breath_id_lag2same','u_out_lag2']\n",
    "x_columns = [col for col in data_train_df.columns if col not in drop_columns]\n",
    "y_columns = ['pressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d17a06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.496865Z",
     "iopub.status.busy": "2021-10-30T16:13:40.496865Z",
     "iopub.status.idle": "2021-10-30T16:13:40.954666Z",
     "shell.execute_reply": "2021-10-30T16:13:40.954666Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = data_train_df[x_columns].values.astype(np.float32)\n",
    "data_train = data_train.reshape(-1, 80, data_train.shape[-1])\n",
    "\n",
    "target_train = data_train_df[y_columns].values.astype(np.float32)\n",
    "target_train = target_train.reshape(-1, 80, target_train.shape[-1])\n",
    "\n",
    "data_test = data_test_df[x_columns].values.astype(np.float32)\n",
    "data_test = data_test.reshape(-1, 80, data_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0e206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75450, 80, 5)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab5d58bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.958655Z",
     "iopub.status.busy": "2021-10-30T16:13:40.958655Z",
     "iopub.status.idle": "2021-10-30T16:13:40.970637Z",
     "shell.execute_reply": "2021-10-30T16:13:40.970637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60360 15090\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(121212)\n",
    "data_idx = np.arange(len(data_train))\n",
    "np.random.shuffle(data_idx)\n",
    "\n",
    "train_index = data_idx[:int(len(data_idx)*0.8)]\n",
    "valid_index = data_idx[int(len(data_idx)*0.8):]\n",
    "\n",
    "print(len(train_index), len(valid_index))\n",
    "\n",
    "x_train, y_train = data_train[train_index], target_train[train_index]\n",
    "x_valid, y_valid = data_train[valid_index], target_train[valid_index]\n",
    "x_test = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7667354f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:41.083361Z",
     "iopub.status.busy": "2021-10-30T16:13:41.083361Z",
     "iopub.status.idle": "2021-10-30T16:13:41.097342Z",
     "shell.execute_reply": "2021-10-30T16:13:41.098340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_train_df\n",
    "del data_test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d692dd27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:41.100334Z",
     "iopub.status.busy": "2021-10-30T16:13:41.100334Z",
     "iopub.status.idle": "2021-10-30T16:13:42.369350Z",
     "shell.execute_reply": "2021-10-30T16:13:42.370347Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluate_num:   3,focus:0.8000: 3it [00:00, ?it/s]\n",
      "evaluate_num:   3,focus:0.8000: 3it [00:00, ?it/s]\n",
      "evaluate_num:  32,focus:0.6000: 32it [00:00, 2005.25it/s]\n",
      "evaluate_num:  25,focus:0.6000: 25it [00:00, 1563.90it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate_list = [evaluate_build(x_test[..., i], evaluate_num) for i in range(x_test.shape[-1])]\n",
    "evaluate_focus_list = []\n",
    "for evaluate in evaluate_list:\n",
    "    focus = 1 - (len(evaluate) - 1)/10\n",
    "    if focus < focus_min:\n",
    "        focus = focus_min\n",
    "    evaluate_focus = focus_build(evaluate, focus)\n",
    "    evaluate_focus_list.append(evaluate_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153da271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:42.373340Z",
     "iopub.status.busy": "2021-10-30T16:13:42.373340Z",
     "iopub.status.idle": "2021-10-30T16:13:42.385326Z",
     "shell.execute_reply": "2021-10-30T16:13:42.386322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_test(\n",
      "  (hw_layer): hw_layer(\n",
      "    (evaluate_list): ModuleList(\n",
      "      (0): Embedding(3, 1)\n",
      "      (1): Embedding(3, 1)\n",
      "      (2): Embedding(32, 1)\n",
      "      (3): Embedding(25, 1)\n",
      "      (4): Embedding(2, 1)\n",
      "    )\n",
      "    (focus_list): ModuleList(\n",
      "      (0): Embedding(3, 1)\n",
      "      (1): Embedding(3, 1)\n",
      "      (2): Embedding(32, 1)\n",
      "      (3): Embedding(25, 1)\n",
      "      (4): Embedding(2, 1)\n",
      "    )\n",
      "  )\n",
      "  (net_block_list): ModuleList(\n",
      "    (0): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (1): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (2): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (3): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (4): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (5): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (6): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (7): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (8): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (9): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (10): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (11): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (12): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (13): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (14): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (15): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (16): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (17): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (18): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (19): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (20): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (21): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (22): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (23): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (24): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (25): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (26): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (27): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (28): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (29): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (30): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "    (31): Net_block(\n",
      "      (lstm): LSTM(65, 65, batch_first=True, bidirectional=True)\n",
      "      (fc): Linear(in_features=130, out_features=65, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=65, out_features=32, bias=False)\n",
      "    (1): SELU()\n",
      "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2471073 130\n"
     ]
    }
   ],
   "source": [
    "model = Net_test(evaluate_focus_list)\n",
    "print(model)\n",
    "\n",
    "train_parameter_num, freeze_parameter_num = net_parameter_count(model)\n",
    "print(train_parameter_num, freeze_parameter_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29404531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_submission(epoch_num, batch_size):\n",
    "    dataLoads = dataLoads_build(x_train, y_train, x_valid, y_valid, batch_size)\n",
    "    learn = Learner(dataLoads, model, loss_func=L1LossFlat())\n",
    "    learn.lr_find()\n",
    "    learn.fit_one_cycle(epoch_num, lr_max=2e-3, cbs=[ReduceLROnPlateau(monitor='valid_loss', min_delta=0.5, patience=10),\n",
    "                                                     SaveModelCallback(monitor='valid_loss', fname=f'{fname}_B{batch_size}_best')])\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    state_dict = torch.load(f'models/{fname}_B{batch_size}_best.pth')\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    loss = torch_valid([model.to(device)], L1LossFlat(), (x_train, y_train),  batch_size, to_device=device)\n",
    "    valid_loss = torch_valid([model.to(device)], L1LossFlat(), (x_valid, y_valid),  batch_size, to_device=device)\n",
    "\n",
    "    print(loss, valid_loss)\n",
    "\n",
    "    predict = torch_predict([model.to(device)], x_test, batch_size, to_device=device)\n",
    "    predict = np.reshape(predict, (-1))\n",
    "\n",
    "    df = pd.read_csv('Database/sample_submission.csv', index_col=0)\n",
    "    df['pressure'] = predict\n",
    "\n",
    "    df.to_csv(f'Submission/{fname}_B{batch_size}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80d97e42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.583700</td>\n",
       "      <td>3.319619</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.367189</td>\n",
       "      <td>1.274281</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.969242</td>\n",
       "      <td>0.945887</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.836877</td>\n",
       "      <td>0.836818</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.748379</td>\n",
       "      <td>0.760986</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.689707</td>\n",
       "      <td>0.675799</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.649318</td>\n",
       "      <td>0.642407</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.613650</td>\n",
       "      <td>0.603546</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.593270</td>\n",
       "      <td>0.594439</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.589611</td>\n",
       "      <td>0.654626</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.591425</td>\n",
       "      <td>0.608990</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.535017</td>\n",
       "      <td>0.532551</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.518543</td>\n",
       "      <td>0.527610</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.498076</td>\n",
       "      <td>0.506218</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.493123</td>\n",
       "      <td>0.548238</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.477294</td>\n",
       "      <td>0.481946</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.466708</td>\n",
       "      <td>0.463530</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.465373</td>\n",
       "      <td>0.480288</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.443689</td>\n",
       "      <td>0.456007</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.430642</td>\n",
       "      <td>0.450776</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.416327</td>\n",
       "      <td>0.426832</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.421378</td>\n",
       "      <td>0.448853</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.406569</td>\n",
       "      <td>0.420717</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.398072</td>\n",
       "      <td>0.410970</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.387812</td>\n",
       "      <td>0.391999</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.385137</td>\n",
       "      <td>0.388678</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.374034</td>\n",
       "      <td>0.375133</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.368875</td>\n",
       "      <td>0.380554</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.355714</td>\n",
       "      <td>0.377672</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.351102</td>\n",
       "      <td>0.375135</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.351508</td>\n",
       "      <td>0.380174</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.341516</td>\n",
       "      <td>0.353867</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.342853</td>\n",
       "      <td>0.361197</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.331450</td>\n",
       "      <td>0.348718</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.323099</td>\n",
       "      <td>0.343112</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.319166</td>\n",
       "      <td>0.337121</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.308981</td>\n",
       "      <td>0.345590</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.312934</td>\n",
       "      <td>0.336783</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.307632</td>\n",
       "      <td>0.332845</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.306022</td>\n",
       "      <td>0.333461</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.299583</td>\n",
       "      <td>0.324486</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.297274</td>\n",
       "      <td>0.327944</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.299217</td>\n",
       "      <td>0.327840</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.292256</td>\n",
       "      <td>0.334002</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.281894</td>\n",
       "      <td>0.318094</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.280036</td>\n",
       "      <td>0.315407</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.279052</td>\n",
       "      <td>0.333129</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.275270</td>\n",
       "      <td>0.316933</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.271032</td>\n",
       "      <td>0.310332</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.263785</td>\n",
       "      <td>0.305792</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.261555</td>\n",
       "      <td>0.304152</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.257635</td>\n",
       "      <td>0.306264</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.252347</td>\n",
       "      <td>0.305033</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.250497</td>\n",
       "      <td>0.303652</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.246522</td>\n",
       "      <td>0.299877</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.242485</td>\n",
       "      <td>0.296278</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.241083</td>\n",
       "      <td>0.294837</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.236838</td>\n",
       "      <td>0.293866</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.235899</td>\n",
       "      <td>0.291708</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.229300</td>\n",
       "      <td>0.289574</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.230630</td>\n",
       "      <td>0.288823</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.291367</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.222267</td>\n",
       "      <td>0.286278</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.218584</td>\n",
       "      <td>0.282162</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.215634</td>\n",
       "      <td>0.280980</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.212455</td>\n",
       "      <td>0.281472</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.209816</td>\n",
       "      <td>0.286629</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.205550</td>\n",
       "      <td>0.279072</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.204873</td>\n",
       "      <td>0.278053</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.201039</td>\n",
       "      <td>0.275381</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.197338</td>\n",
       "      <td>0.276780</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.196161</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.193137</td>\n",
       "      <td>0.272885</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.189122</td>\n",
       "      <td>0.272558</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.186762</td>\n",
       "      <td>0.271838</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.186413</td>\n",
       "      <td>0.270867</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.182477</td>\n",
       "      <td>0.269996</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.182158</td>\n",
       "      <td>0.269819</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.178073</td>\n",
       "      <td>0.268017</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.176476</td>\n",
       "      <td>0.267909</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.175505</td>\n",
       "      <td>0.266615</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.174184</td>\n",
       "      <td>0.266929</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.172117</td>\n",
       "      <td>0.266112</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.169189</td>\n",
       "      <td>0.265504</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.167343</td>\n",
       "      <td>0.265509</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.165425</td>\n",
       "      <td>0.265083</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.167029</td>\n",
       "      <td>0.264961</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.164007</td>\n",
       "      <td>0.264564</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.161889</td>\n",
       "      <td>0.264714</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.162964</td>\n",
       "      <td>0.264222</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.160394</td>\n",
       "      <td>0.264214</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.159424</td>\n",
       "      <td>0.264192</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.157630</td>\n",
       "      <td>0.263876</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.157929</td>\n",
       "      <td>0.263874</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.156874</td>\n",
       "      <td>0.263808</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.157867</td>\n",
       "      <td>0.263730</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.157933</td>\n",
       "      <td>0.263759</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.157925</td>\n",
       "      <td>0.263745</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.156639</td>\n",
       "      <td>0.263741</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.156891</td>\n",
       "      <td>0.263734</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 3.3196191787719727.\n",
      "Better model found at epoch 1 with valid_loss value: 1.2742809057235718.\n",
      "Better model found at epoch 2 with valid_loss value: 0.9458868503570557.\n",
      "Better model found at epoch 3 with valid_loss value: 0.8368184566497803.\n",
      "Better model found at epoch 4 with valid_loss value: 0.760985791683197.\n",
      "Better model found at epoch 5 with valid_loss value: 0.6757994294166565.\n",
      "Better model found at epoch 6 with valid_loss value: 0.642407238483429.\n",
      "Better model found at epoch 7 with valid_loss value: 0.6035457253456116.\n",
      "Better model found at epoch 8 with valid_loss value: 0.5944392681121826.\n",
      "Better model found at epoch 11 with valid_loss value: 0.5325505137443542.\n",
      "Better model found at epoch 12 with valid_loss value: 0.5276104807853699.\n",
      "Better model found at epoch 13 with valid_loss value: 0.5062183737754822.\n",
      "Epoch 14: reducing lr to 0.0001336466434315312\n",
      "Better model found at epoch 15 with valid_loss value: 0.48194578289985657.\n",
      "Better model found at epoch 16 with valid_loss value: 0.4635302424430847.\n",
      "Better model found at epoch 18 with valid_loss value: 0.45600655674934387.\n",
      "Better model found at epoch 19 with valid_loss value: 0.4507763683795929.\n",
      "Better model found at epoch 20 with valid_loss value: 0.4268322288990021.\n",
      "Better model found at epoch 22 with valid_loss value: 0.4207170903682709.\n",
      "Better model found at epoch 23 with valid_loss value: 0.41096964478492737.\n",
      "Better model found at epoch 24 with valid_loss value: 0.39199933409690857.\n",
      "Epoch 24: reducing lr to 0.0001999999979225561\n",
      "Better model found at epoch 25 with valid_loss value: 0.3886782228946686.\n",
      "Better model found at epoch 26 with valid_loss value: 0.37513279914855957.\n",
      "Better model found at epoch 31 with valid_loss value: 0.35386723279953003.\n",
      "Better model found at epoch 33 with valid_loss value: 0.34871771931648254.\n",
      "Better model found at epoch 34 with valid_loss value: 0.34311190247535706.\n",
      "Epoch 34: reducing lr to 0.00019135745101272935\n",
      "Better model found at epoch 35 with valid_loss value: 0.33712124824523926.\n",
      "Better model found at epoch 37 with valid_loss value: 0.33678296208381653.\n",
      "Better model found at epoch 38 with valid_loss value: 0.33284518122673035.\n",
      "Better model found at epoch 40 with valid_loss value: 0.32448625564575195.\n",
      "Better model found at epoch 44 with valid_loss value: 0.3180936872959137.\n",
      "Epoch 44: reducing lr to 0.00016691854379352361\n",
      "Better model found at epoch 45 with valid_loss value: 0.3154071867465973.\n",
      "Better model found at epoch 48 with valid_loss value: 0.3103322386741638.\n",
      "Better model found at epoch 49 with valid_loss value: 0.30579161643981934.\n",
      "Better model found at epoch 50 with valid_loss value: 0.3041515648365021.\n",
      "Better model found at epoch 53 with valid_loss value: 0.3036517798900604.\n",
      "Better model found at epoch 54 with valid_loss value: 0.29987671971321106.\n",
      "Epoch 54: reducing lr to 0.0001309089866847191\n",
      "Better model found at epoch 55 with valid_loss value: 0.29627755284309387.\n",
      "Better model found at epoch 56 with valid_loss value: 0.29483675956726074.\n",
      "Better model found at epoch 57 with valid_loss value: 0.29386645555496216.\n",
      "Better model found at epoch 58 with valid_loss value: 0.2917075455188751.\n",
      "Better model found at epoch 59 with valid_loss value: 0.2895740568637848.\n",
      "Better model found at epoch 60 with valid_loss value: 0.2888227701187134.\n",
      "Better model found at epoch 62 with valid_loss value: 0.28627777099609375.\n",
      "Better model found at epoch 63 with valid_loss value: 0.28216156363487244.\n",
      "Better model found at epoch 64 with valid_loss value: 0.280979722738266.\n",
      "Epoch 64: reducing lr to 8.955513989290548e-05\n",
      "Better model found at epoch 67 with valid_loss value: 0.2790716290473938.\n",
      "Better model found at epoch 68 with valid_loss value: 0.27805307507514954.\n",
      "Better model found at epoch 69 with valid_loss value: 0.27538126707077026.\n",
      "Better model found at epoch 71 with valid_loss value: 0.2742558717727661.\n",
      "Better model found at epoch 72 with valid_loss value: 0.2728852927684784.\n",
      "Better model found at epoch 73 with valid_loss value: 0.27255818247795105.\n",
      "Better model found at epoch 74 with valid_loss value: 0.27183762192726135.\n",
      "Epoch 74: reducing lr to 5.00075110245173e-05\n",
      "Better model found at epoch 75 with valid_loss value: 0.27086713910102844.\n",
      "Better model found at epoch 76 with valid_loss value: 0.26999619603157043.\n",
      "Better model found at epoch 77 with valid_loss value: 0.26981881260871887.\n",
      "Better model found at epoch 78 with valid_loss value: 0.268016517162323.\n",
      "Better model found at epoch 79 with valid_loss value: 0.2679086923599243.\n",
      "Better model found at epoch 80 with valid_loss value: 0.2666146159172058.\n",
      "Better model found at epoch 82 with valid_loss value: 0.2661115527153015.\n",
      "Better model found at epoch 83 with valid_loss value: 0.265504390001297.\n",
      "Epoch 84: reducing lr to 1.9104179931059522e-05\n",
      "Better model found at epoch 85 with valid_loss value: 0.2650829255580902.\n",
      "Better model found at epoch 86 with valid_loss value: 0.2649606168270111.\n",
      "Better model found at epoch 87 with valid_loss value: 0.2645636796951294.\n",
      "Better model found at epoch 89 with valid_loss value: 0.26422154903411865.\n",
      "Better model found at epoch 90 with valid_loss value: 0.2642136812210083.\n",
      "Better model found at epoch 91 with valid_loss value: 0.2641916275024414.\n",
      "Better model found at epoch 92 with valid_loss value: 0.2638755440711975.\n",
      "Better model found at epoch 93 with valid_loss value: 0.2638743817806244.\n",
      "Better model found at epoch 94 with valid_loss value: 0.26380816102027893.\n",
      "Epoch 94: reducing lr to 2.1886624206054943e-06\n",
      "Better model found at epoch 95 with valid_loss value: 0.2637301981449127.\n",
      "0.1571124413155562 0.26372280894525796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prodict: 100% 503/503 [00:26<00:00, 19.26it/s]\n",
      "C:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_submission(epoch_num_first, batch_size_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f40a46ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.158152</td>\n",
       "      <td>0.263832</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.157549</td>\n",
       "      <td>0.263897</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.157478</td>\n",
       "      <td>0.263855</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.157635</td>\n",
       "      <td>0.263880</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.157285</td>\n",
       "      <td>0.263995</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157482</td>\n",
       "      <td>0.263985</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.157611</td>\n",
       "      <td>0.264032</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.157593</td>\n",
       "      <td>0.264089</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.157598</td>\n",
       "      <td>0.264092</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.157922</td>\n",
       "      <td>0.264281</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.157598</td>\n",
       "      <td>0.264352</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.157809</td>\n",
       "      <td>0.264175</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.158054</td>\n",
       "      <td>0.264754</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.157902</td>\n",
       "      <td>0.264866</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.158362</td>\n",
       "      <td>0.264546</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.158255</td>\n",
       "      <td>0.264755</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.158352</td>\n",
       "      <td>0.264950</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.158740</td>\n",
       "      <td>0.265486</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.159076</td>\n",
       "      <td>0.264758</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.159014</td>\n",
       "      <td>0.265443</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.159425</td>\n",
       "      <td>0.265905</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.159595</td>\n",
       "      <td>0.265974</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.160007</td>\n",
       "      <td>0.264782</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.160585</td>\n",
       "      <td>0.265594</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.160558</td>\n",
       "      <td>0.265909</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.160680</td>\n",
       "      <td>0.265926</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.161412</td>\n",
       "      <td>0.265413</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.161526</td>\n",
       "      <td>0.265580</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.162181</td>\n",
       "      <td>0.266440</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.163247</td>\n",
       "      <td>0.267041</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.164392</td>\n",
       "      <td>0.266012</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.163497</td>\n",
       "      <td>0.266895</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.163844</td>\n",
       "      <td>0.266025</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.165727</td>\n",
       "      <td>0.271217</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.165551</td>\n",
       "      <td>0.271162</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.165637</td>\n",
       "      <td>0.266389</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.166580</td>\n",
       "      <td>0.268349</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.167256</td>\n",
       "      <td>0.266957</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.167921</td>\n",
       "      <td>0.265706</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.168346</td>\n",
       "      <td>0.272349</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.167946</td>\n",
       "      <td>0.266277</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.167955</td>\n",
       "      <td>0.272048</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.169075</td>\n",
       "      <td>0.266400</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.169689</td>\n",
       "      <td>0.266936</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.169111</td>\n",
       "      <td>0.265967</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.169934</td>\n",
       "      <td>0.266809</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.169178</td>\n",
       "      <td>0.267007</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.170258</td>\n",
       "      <td>0.273427</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.170150</td>\n",
       "      <td>0.266776</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.169741</td>\n",
       "      <td>0.269369</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.169615</td>\n",
       "      <td>0.270326</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.168346</td>\n",
       "      <td>0.266589</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.169380</td>\n",
       "      <td>0.268709</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.168340</td>\n",
       "      <td>0.266051</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.167544</td>\n",
       "      <td>0.270936</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.167610</td>\n",
       "      <td>0.266371</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.167018</td>\n",
       "      <td>0.266180</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.168320</td>\n",
       "      <td>0.272824</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.166924</td>\n",
       "      <td>0.263662</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.165863</td>\n",
       "      <td>0.268153</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.165383</td>\n",
       "      <td>0.265394</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.165652</td>\n",
       "      <td>0.264044</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.166405</td>\n",
       "      <td>0.264213</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.164624</td>\n",
       "      <td>0.264237</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.164931</td>\n",
       "      <td>0.266066</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.164153</td>\n",
       "      <td>0.264793</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.162777</td>\n",
       "      <td>0.266357</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.162750</td>\n",
       "      <td>0.264647</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.162532</td>\n",
       "      <td>0.266805</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.163225</td>\n",
       "      <td>0.268049</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.161249</td>\n",
       "      <td>0.269941</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.161151</td>\n",
       "      <td>0.264621</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.161311</td>\n",
       "      <td>0.263125</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.161865</td>\n",
       "      <td>0.262738</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.160538</td>\n",
       "      <td>0.263470</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.160349</td>\n",
       "      <td>0.270964</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.159462</td>\n",
       "      <td>0.268029</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.159468</td>\n",
       "      <td>0.263074</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.157687</td>\n",
       "      <td>0.265370</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.157686</td>\n",
       "      <td>0.265767</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.157604</td>\n",
       "      <td>0.262313</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.156515</td>\n",
       "      <td>0.263970</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.155327</td>\n",
       "      <td>0.262354</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.156111</td>\n",
       "      <td>0.262633</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.155616</td>\n",
       "      <td>0.262270</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.154572</td>\n",
       "      <td>0.262077</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.154727</td>\n",
       "      <td>0.261960</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.154754</td>\n",
       "      <td>0.265116</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.153435</td>\n",
       "      <td>0.262296</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.153966</td>\n",
       "      <td>0.263103</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.152092</td>\n",
       "      <td>0.260192</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.151887</td>\n",
       "      <td>0.263587</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.150998</td>\n",
       "      <td>0.261234</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.151011</td>\n",
       "      <td>0.261393</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.151004</td>\n",
       "      <td>0.261440</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.149777</td>\n",
       "      <td>0.264039</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.149130</td>\n",
       "      <td>0.260985</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.148801</td>\n",
       "      <td>0.260514</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.147175</td>\n",
       "      <td>0.260529</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.147670</td>\n",
       "      <td>0.260726</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.147788</td>\n",
       "      <td>0.261158</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.146305</td>\n",
       "      <td>0.261808</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.145536</td>\n",
       "      <td>0.260795</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.145040</td>\n",
       "      <td>0.259981</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.145901</td>\n",
       "      <td>0.261525</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.144094</td>\n",
       "      <td>0.260378</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.143805</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.144077</td>\n",
       "      <td>0.259914</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.143020</td>\n",
       "      <td>0.263089</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.143480</td>\n",
       "      <td>0.261831</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.142516</td>\n",
       "      <td>0.259651</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.142284</td>\n",
       "      <td>0.260087</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.140961</td>\n",
       "      <td>0.261080</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.141102</td>\n",
       "      <td>0.260465</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.140061</td>\n",
       "      <td>0.259266</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.140390</td>\n",
       "      <td>0.258596</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.138278</td>\n",
       "      <td>0.258902</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.137759</td>\n",
       "      <td>0.259517</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.137585</td>\n",
       "      <td>0.259564</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.137393</td>\n",
       "      <td>0.260955</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.136699</td>\n",
       "      <td>0.260252</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.136072</td>\n",
       "      <td>0.259832</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.136199</td>\n",
       "      <td>0.259274</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.135250</td>\n",
       "      <td>0.258837</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.134536</td>\n",
       "      <td>0.262779</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.134781</td>\n",
       "      <td>0.258999</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.134246</td>\n",
       "      <td>0.258481</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.133580</td>\n",
       "      <td>0.259918</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.133787</td>\n",
       "      <td>0.258869</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.132166</td>\n",
       "      <td>0.258609</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.131930</td>\n",
       "      <td>0.258711</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.131204</td>\n",
       "      <td>0.258977</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.131141</td>\n",
       "      <td>0.260081</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.131058</td>\n",
       "      <td>0.259658</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.130205</td>\n",
       "      <td>0.258880</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.130492</td>\n",
       "      <td>0.259156</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.130001</td>\n",
       "      <td>0.258769</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.128880</td>\n",
       "      <td>0.258701</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.129473</td>\n",
       "      <td>0.259039</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.128488</td>\n",
       "      <td>0.258705</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.127958</td>\n",
       "      <td>0.258769</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.127402</td>\n",
       "      <td>0.258546</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.127191</td>\n",
       "      <td>0.258667</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.126602</td>\n",
       "      <td>0.258593</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.126784</td>\n",
       "      <td>0.258739</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.125925</td>\n",
       "      <td>0.259059</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.125762</td>\n",
       "      <td>0.258728</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.125204</td>\n",
       "      <td>0.258867</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.125221</td>\n",
       "      <td>0.258795</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.124461</td>\n",
       "      <td>0.258828</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.124395</td>\n",
       "      <td>0.259021</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.124108</td>\n",
       "      <td>0.258815</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.123580</td>\n",
       "      <td>0.259256</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.123258</td>\n",
       "      <td>0.258999</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.122693</td>\n",
       "      <td>0.258975</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.122410</td>\n",
       "      <td>0.258735</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.122364</td>\n",
       "      <td>0.258899</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.122111</td>\n",
       "      <td>0.259081</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.121832</td>\n",
       "      <td>0.259009</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.121484</td>\n",
       "      <td>0.258850</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.121122</td>\n",
       "      <td>0.258769</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.121032</td>\n",
       "      <td>0.258853</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.120631</td>\n",
       "      <td>0.258765</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>0.258832</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.120062</td>\n",
       "      <td>0.258630</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.119689</td>\n",
       "      <td>0.258960</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.119278</td>\n",
       "      <td>0.258969</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.119212</td>\n",
       "      <td>0.258948</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.118977</td>\n",
       "      <td>0.258856</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.118960</td>\n",
       "      <td>0.258815</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.118655</td>\n",
       "      <td>0.259005</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.118573</td>\n",
       "      <td>0.258823</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.118226</td>\n",
       "      <td>0.259018</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.117985</td>\n",
       "      <td>0.259056</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.117773</td>\n",
       "      <td>0.259129</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.117673</td>\n",
       "      <td>0.259150</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.117593</td>\n",
       "      <td>0.259102</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.117403</td>\n",
       "      <td>0.259112</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.117226</td>\n",
       "      <td>0.259211</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.117179</td>\n",
       "      <td>0.259179</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.116904</td>\n",
       "      <td>0.259140</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.116887</td>\n",
       "      <td>0.259226</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.116623</td>\n",
       "      <td>0.259160</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.116699</td>\n",
       "      <td>0.259269</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.116561</td>\n",
       "      <td>0.259167</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.116337</td>\n",
       "      <td>0.259229</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.116212</td>\n",
       "      <td>0.259209</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.116226</td>\n",
       "      <td>0.259238</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.116086</td>\n",
       "      <td>0.259262</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.116052</td>\n",
       "      <td>0.259266</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.116117</td>\n",
       "      <td>0.259261</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.116018</td>\n",
       "      <td>0.259275</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.115862</td>\n",
       "      <td>0.259261</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.115869</td>\n",
       "      <td>0.259285</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.115826</td>\n",
       "      <td>0.259286</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.115690</td>\n",
       "      <td>0.259269</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.115814</td>\n",
       "      <td>0.259274</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.115815</td>\n",
       "      <td>0.259283</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.115758</td>\n",
       "      <td>0.259280</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.115781</td>\n",
       "      <td>0.259282</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.2638324499130249.\n",
      "Epoch 10: reducing lr to 2.99801642559225e-05\n",
      "Epoch 20: reducing lr to 8.004890305450764e-05\n",
      "Epoch 30: reducing lr to 0.00013926615412367807\n",
      "Epoch 40: reducing lr to 0.0001850129258187834\n",
      "Epoch 50: reducing lr to 0.00019997864179833354\n",
      "Better model found at epoch 58 with valid_loss value: 0.2636618912220001.\n",
      "Epoch 60: reducing lr to 0.00019736420628453443\n",
      "Epoch 70: reducing lr to 0.00019049452886110184\n",
      "Better model found at epoch 72 with valid_loss value: 0.2631247639656067.\n",
      "Better model found at epoch 73 with valid_loss value: 0.26273754239082336.\n",
      "Better model found at epoch 80 with valid_loss value: 0.2623126208782196.\n",
      "Epoch 80: reducing lr to 0.0001796698577201928\n",
      "Better model found at epoch 84 with valid_loss value: 0.26227009296417236.\n",
      "Better model found at epoch 85 with valid_loss value: 0.2620769739151001.\n",
      "Better model found at epoch 86 with valid_loss value: 0.26195982098579407.\n",
      "Better model found at epoch 90 with valid_loss value: 0.26019158959388733.\n",
      "Epoch 90: reducing lr to 0.00016536326808994537\n",
      "Epoch 100: reducing lr to 0.0001482000368697763\n",
      "Better model found at epoch 103 with valid_loss value: 0.2599813938140869.\n",
      "Better model found at epoch 107 with valid_loss value: 0.2599135935306549.\n",
      "Better model found at epoch 110 with valid_loss value: 0.2596513628959656.\n",
      "Epoch 110: reducing lr to 0.00012893027670395768\n",
      "Better model found at epoch 114 with valid_loss value: 0.25926560163497925.\n",
      "Better model found at epoch 115 with valid_loss value: 0.25859567523002625.\n",
      "Epoch 120: reducing lr to 0.00010839615914874569\n",
      "Better model found at epoch 126 with valid_loss value: 0.25848135352134705.\n",
      "Epoch 130: reducing lr to 8.749514186010556e-05\n",
      "Epoch 140: reducing lr to 6.714067283172844e-05\n",
      "Epoch 150: reducing lr to 4.822239220903682e-05\n",
      "Epoch 160: reducing lr to 3.156706725405778e-05\n",
      "Epoch 170: reducing lr to 1.790263318728145e-05\n",
      "Epoch 180: reducing lr to 7.826284014674769e-06\n",
      "Epoch 190: reducing lr to 1.778422446453102e-06\n",
      "0.13121376284643224 0.25867362869413274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prodict: 100% 63/63 [00:09<00:00,  6.60it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_submission(epoch_num_second, batch_size_second)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9cf96c7db471cf61b133b0e4e3b2523172ebb61bf8cc081d235291383382076"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
