{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb18dba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:34.441284Z",
     "iopub.status.busy": "2021-10-30T16:13:34.440286Z",
     "iopub.status.idle": "2021-10-30T16:13:36.209240Z",
     "shell.execute_reply": "2021-10-30T16:13:36.209240Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import argparse\n",
    "from fastai.layers import swish\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "from fastai.callback.schedule import Learner\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.losses import L1LossFlat\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.callback.tracker import ReduceLROnPlateau, SaveModelCallback\n",
    "\n",
    "from HW_base import evaluate_build, focus_build\n",
    "from HW_torch import dataLoads_build, net_parameter_count, hw_layer\n",
    "from HW_torch import torch_valid, torch_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be584b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:36.211234Z",
     "iopub.status.busy": "2021-10-30T16:13:36.211234Z",
     "iopub.status.idle": "2021-10-30T16:13:36.225215Z",
     "shell.execute_reply": "2021-10-30T16:13:36.225215Z"
    }
   },
   "outputs": [],
   "source": [
    "fname               = '(F5-E128-F10)_RES(LSTM-FC-HW)x8-(FC-SELU-FC)'\n",
    "evaluate_num        = 128\n",
    "focus_min           = 0.1\n",
    "net_block_num       = 8\n",
    "hw_active           = False\n",
    "epoch_num_first     = 100\n",
    "batch_size_first    = 100\n",
    "epoch_num_second    = 200\n",
    "batch_size_second   = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55110b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:36.231199Z",
     "iopub.status.busy": "2021-10-30T16:13:36.230201Z",
     "iopub.status.idle": "2021-10-30T16:13:36.241180Z",
     "shell.execute_reply": "2021-10-30T16:13:36.241180Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net_block(torch.nn.Module):\n",
    "    def __init__(self, input_dims, internal_dims, output_dims, bias=True, bidirectional=True, batch_first=True, **kwargs):\n",
    "        super(Net_block, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dims, internal_dims, num_layers=1, bias=True, bidirectional=True, batch_first=True)\n",
    "        if bidirectional:\n",
    "            self.fc =nn.Linear(internal_dims*2, output_dims)\n",
    "        else:\n",
    "            self.fc =nn.Linear(internal_dims, output_dims)\n",
    "        self._reinitialize()\n",
    "        \n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        https://www.kaggle.com/junkoda/pytorch-lstm-with-tensorflow-like-initialization/notebook\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'lstm' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "            elif 'fc' in name:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'bias' in name:\n",
    "                    p.data.fill_(0)\n",
    "    \n",
    "    def forward(self, x, hw=None):\n",
    "        y, _ = self.lstm(x)\n",
    "        y = self.fc(y) + x\n",
    "        if hw is not None:\n",
    "            y = y * hw\n",
    "        return y\n",
    "        \n",
    "class Net_test(torch.nn.Module):\n",
    "    def __init__(self, evaluate_dic_list, net_block_num=net_block_num, hw_active=hw_active, **kwargs):\n",
    "        super(Net_test, self).__init__()\n",
    "        self.hw_layer = hw_layer(evaluate_dic_list)\n",
    "        self.hw_dims = self.hw_layer.channels\n",
    "        \n",
    "        self.net_block_list = nn.ModuleList()\n",
    "        for _ in range(net_block_num):\n",
    "            self.net_block_list.append(Net_block(self.hw_dims, self.hw_dims, self.hw_dims))\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(self.hw_dims, 32, bias=False),\n",
    "                                nn.SELU(),\n",
    "                                nn.Linear(32, 1, bias=True))\n",
    "        self._reinitialize()\n",
    "        \n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        https://www.kaggle.com/junkoda/pytorch-lstm-with-tensorflow-like-initialization/notebook\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'lstm' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "            elif 'fc' in name:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'bias' in name:\n",
    "                    p.data.fill_(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hw = self.hw_layer(x)\n",
    "        x = hw\n",
    "        \n",
    "        for net_block in self.net_block_list:\n",
    "            if hw_active:\n",
    "                x = net_block(x, hw)\n",
    "            else:\n",
    "                x = net_block(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b48cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:36.243175Z",
     "iopub.status.busy": "2021-10-30T16:13:36.243175Z",
     "iopub.status.idle": "2021-10-30T16:13:40.477893Z",
     "shell.execute_reply": "2021-10-30T16:13:40.477893Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train_df = pd.read_csv('./Database/train.csv')\n",
    "data_test_df = pd.read_csv('./Database/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f896618a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.479887Z",
     "iopub.status.busy": "2021-10-30T16:13:40.479887Z",
     "iopub.status.idle": "2021-10-30T16:13:40.492874Z",
     "shell.execute_reply": "2021-10-30T16:13:40.493873Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_columns = ['pressure','id', 'breath_id','one','count','breath_id_lag','breath_id_lag2','breath_id_lagsame','breath_id_lag2same','u_out_lag2']\n",
    "x_columns = [col for col in data_train_df.columns if col not in drop_columns]\n",
    "y_columns = ['pressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d17a06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.496865Z",
     "iopub.status.busy": "2021-10-30T16:13:40.496865Z",
     "iopub.status.idle": "2021-10-30T16:13:40.954666Z",
     "shell.execute_reply": "2021-10-30T16:13:40.954666Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = data_train_df[x_columns].values.astype(np.float32)\n",
    "data_train = data_train.reshape(-1, 80, data_train.shape[-1])\n",
    "\n",
    "target_train = data_train_df[y_columns].values.astype(np.float32)\n",
    "target_train = target_train.reshape(-1, 80, target_train.shape[-1])\n",
    "\n",
    "data_test = data_test_df[x_columns].values.astype(np.float32)\n",
    "data_test = data_test.reshape(-1, 80, data_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d58bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.958655Z",
     "iopub.status.busy": "2021-10-30T16:13:40.958655Z",
     "iopub.status.idle": "2021-10-30T16:13:40.970637Z",
     "shell.execute_reply": "2021-10-30T16:13:40.970637Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(121212)\n",
    "data_idx = np.arange(len(data_train))\n",
    "np.random.shuffle(data_idx)\n",
    "\n",
    "train_index = data_idx[:int(len(data_idx)*0.08)]\n",
    "valid_index = data_idx[-int(len(data_idx)*0.02):]\n",
    "\n",
    "print(len(train_index), len(valid_index))\n",
    "\n",
    "x_train, y_train = data_train[train_index], target_train[train_index]\n",
    "x_valid, y_valid = data_train[valid_index], target_train[valid_index]\n",
    "x_test = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7667354f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:41.083361Z",
     "iopub.status.busy": "2021-10-30T16:13:41.083361Z",
     "iopub.status.idle": "2021-10-30T16:13:41.097342Z",
     "shell.execute_reply": "2021-10-30T16:13:41.098340Z"
    }
   },
   "outputs": [],
   "source": [
    "del data_train_df\n",
    "del data_test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d692dd27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:41.100334Z",
     "iopub.status.busy": "2021-10-30T16:13:41.100334Z",
     "iopub.status.idle": "2021-10-30T16:13:42.369350Z",
     "shell.execute_reply": "2021-10-30T16:13:42.370347Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_list = [evaluate_build(x_test[..., i], evaluate_num) for i in range(x_test.shape[-1])]\n",
    "evaluate_focus_list = []\n",
    "for evaluate in evaluate_list:\n",
    "    focus = 1 - (len(evaluate) - 1)/10\n",
    "    if focus < focus_min:\n",
    "        focus = focus_min\n",
    "    evaluate_focus = focus_build(evaluate, focus)\n",
    "    evaluate_focus_list.append(evaluate_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153da271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:42.373340Z",
     "iopub.status.busy": "2021-10-30T16:13:42.373340Z",
     "iopub.status.idle": "2021-10-30T16:13:42.385326Z",
     "shell.execute_reply": "2021-10-30T16:13:42.386322Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Net_test(evaluate_focus_list)\n",
    "print(model)\n",
    "\n",
    "train_parameter_num, freeze_parameter_num = net_parameter_count(model)\n",
    "print(train_parameter_num, freeze_parameter_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29404531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_submission(epoch_num, batch_size):\n",
    "    dataLoads = dataLoads_build(x_train, y_train, x_valid, y_valid, batch_size)\n",
    "    learn = Learner(dataLoads, model, loss_func=L1LossFlat())\n",
    "    learn.lr_find()\n",
    "    learn.fit_one_cycle(epoch_num, lr_max=2e-3, cbs=[ReduceLROnPlateau(monitor='valid_loss', min_delta=0.5, patience=10),\n",
    "                                                     SaveModelCallback(monitor='valid_loss', fname=f'{fname}_B{batch_size}_best')])\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    state_dict = torch.load(f'models/{fname}_B{batch_size}_best.pth')\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    loss = torch_valid([model.to(device)], L1LossFlat(), (x_train, y_train),  batch_size, to_device=device)\n",
    "    valid_loss = torch_valid([model.to(device)], L1LossFlat(), (x_valid, y_valid),  batch_size, to_device=device)\n",
    "\n",
    "    print(loss, valid_loss)\n",
    "\n",
    "    predict = torch_predict([model.to(device)], x_test, batch_size, to_device=device)\n",
    "    predict = np.reshape(predict, (-1))\n",
    "\n",
    "    df = pd.read_csv('Database/sample_submission.csv', index_col=0)\n",
    "    df['pressure'] = predict\n",
    "\n",
    "    df.to_csv(f'Submission/{fname}_B{batch_size}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d97e42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_submission(epoch_num_first, batch_size_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a46ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "0train_submission(epoch_num_second, batch_size_second)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9cf96c7db471cf61b133b0e4e3b2523172ebb61bf8cc081d235291383382076"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
