{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17dfe55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, LearningRateScheduler, ReduceLROnPlateau\n",
    "\n",
    "from HW_base import evaluate_build, focus_build\n",
    "from HW_keras import hw_layer\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15456512",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ec9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843aa0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = np.min(x_train, axis=(1, 2), keepdims=True)\n",
    "x_max = np.max(x_train, axis=(1, 2), keepdims=True)\n",
    "x_train = (x_train - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6b2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = np.min(x_test, axis=(1, 2), keepdims=True)\n",
    "x_max = np.max(x_test, axis=(1, 2), keepdims=True)\n",
    "x_test = (x_test - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92ab5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluate_num:   8,focus:0.8000: 8it [00:00, ?it/s]\n",
      "evaluate_num:   8,focus:0.8000: 8it [00:00, 8012.04it/s]\n",
      "evaluate_num:   8,focus:0.8000: 8it [00:00, 8027.38it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate_list = [evaluate_build(x_test[..., i], 8) for i in range(x_test.shape[-1])]\n",
    "evaluate_focus_list = [focus_build(evaluate, 0.8) for evaluate in evaluate_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9aee56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hw_layer (hw_layer)          (None, 32, 32, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 1, 1, 10)          245770    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 245,770\n",
      "Trainable params: 245,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(hw_layer(evaluate_focus_list, input_shape=(32, 32, 3), name='hw_layer'))\n",
    "model.add(Conv2D(10, (32, 32)))\n",
    "\n",
    "# model.add(Conv2D(10, (32, 32), input_shape=(32, 32, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21177d2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "100/100 [==============================] - 4s 15ms/step - loss: 1.8589 - accuracy: 0.3605 - val_loss: 1.7421 - val_accuracy: 0.3996\n",
      "Epoch 2/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.5997 - accuracy: 0.4541 - val_loss: 1.7079 - val_accuracy: 0.4217\n",
      "Epoch 3/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.4817 - accuracy: 0.5000 - val_loss: 1.7608 - val_accuracy: 0.3964\n",
      "Epoch 4/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.3892 - accuracy: 0.5338 - val_loss: 1.7577 - val_accuracy: 0.3934\n",
      "Epoch 5/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.3168 - accuracy: 0.5649 - val_loss: 1.7784 - val_accuracy: 0.3891\n",
      "Epoch 6/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.2541 - accuracy: 0.5876 - val_loss: 1.8236 - val_accuracy: 0.3994\n",
      "Epoch 7/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.2065 - accuracy: 0.6066 - val_loss: 1.8313 - val_accuracy: 0.3956\n",
      "Epoch 8/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.1423 - accuracy: 0.6314 - val_loss: 1.8396 - val_accuracy: 0.3904\n",
      "Epoch 9/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.0948 - accuracy: 0.6513 - val_loss: 1.8757 - val_accuracy: 0.3853\n",
      "Epoch 10/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.0560 - accuracy: 0.6655 - val_loss: 1.8998 - val_accuracy: 0.3771\n",
      "Epoch 11/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.0194 - accuracy: 0.6798 - val_loss: 1.9355 - val_accuracy: 0.3676\n",
      "Epoch 12/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.9849 - accuracy: 0.6923 - val_loss: 1.9851 - val_accuracy: 0.3667\n",
      "Epoch 13/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.9514 - accuracy: 0.7053 - val_loss: 1.9857 - val_accuracy: 0.3658\n",
      "Epoch 14/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.9236 - accuracy: 0.7154 - val_loss: 2.0423 - val_accuracy: 0.3480\n",
      "Epoch 15/200\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.8989 - accuracy: 0.7243 - val_loss: 2.0157 - val_accuracy: 0.3634\n",
      "Epoch 16/200\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.8779 - accuracy: 0.7309 - val_loss: 2.0736 - val_accuracy: 0.3603\n",
      "Epoch 17/200\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.8466 - accuracy: 0.7465 - val_loss: 2.0954 - val_accuracy: 0.3569\n",
      "Epoch 18/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.8236 - accuracy: 0.7526 - val_loss: 2.0996 - val_accuracy: 0.3556\n",
      "Epoch 19/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.8078 - accuracy: 0.7588 - val_loss: 2.1361 - val_accuracy: 0.3556\n",
      "Epoch 20/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.7842 - accuracy: 0.7692 - val_loss: 2.1421 - val_accuracy: 0.3515\n",
      "Epoch 21/200\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.7624 - accuracy: 0.7793 - val_loss: 2.1682 - val_accuracy: 0.3539\n",
      "Epoch 22/200\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.7367 - accuracy: 0.7901 - val_loss: 2.2073 - val_accuracy: 0.3514\n",
      "Epoch 23/200\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.7247 - accuracy: 0.7924 - val_loss: 2.2334 - val_accuracy: 0.3489\n",
      "Epoch 24/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.7072 - accuracy: 0.8007 - val_loss: 2.2240 - val_accuracy: 0.3504\n",
      "Epoch 25/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6864 - accuracy: 0.8093 - val_loss: 2.2969 - val_accuracy: 0.3474\n",
      "Epoch 26/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6711 - accuracy: 0.8157 - val_loss: 2.2980 - val_accuracy: 0.3501\n",
      "Epoch 27/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6515 - accuracy: 0.8235 - val_loss: 2.3055 - val_accuracy: 0.3410\n",
      "Epoch 28/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6403 - accuracy: 0.8286 - val_loss: 2.3329 - val_accuracy: 0.3453\n",
      "Epoch 29/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6282 - accuracy: 0.8333 - val_loss: 2.3657 - val_accuracy: 0.3394\n",
      "Epoch 30/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6156 - accuracy: 0.8369 - val_loss: 2.3804 - val_accuracy: 0.3442\n",
      "Epoch 31/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6063 - accuracy: 0.8386 - val_loss: 2.4080 - val_accuracy: 0.3324\n",
      "Epoch 32/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5865 - accuracy: 0.8488 - val_loss: 2.4195 - val_accuracy: 0.3371\n",
      "Epoch 33/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5783 - accuracy: 0.8504 - val_loss: 2.4585 - val_accuracy: 0.3341\n",
      "Epoch 34/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5614 - accuracy: 0.8597 - val_loss: 2.4889 - val_accuracy: 0.3329\n",
      "Epoch 35/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5508 - accuracy: 0.8630 - val_loss: 2.4869 - val_accuracy: 0.3347\n",
      "Epoch 36/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5415 - accuracy: 0.8655 - val_loss: 2.5176 - val_accuracy: 0.3328\n",
      "Epoch 37/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5300 - accuracy: 0.8699 - val_loss: 2.5298 - val_accuracy: 0.3333\n",
      "Epoch 38/200\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.5183 - accuracy: 0.8746 - val_loss: 2.5987 - val_accuracy: 0.3273\n",
      "Epoch 39/200\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.5016 - accuracy: 0.8843 - val_loss: 2.5857 - val_accuracy: 0.3280\n",
      "Epoch 40/200\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.4982 - accuracy: 0.8824 - val_loss: 2.6069 - val_accuracy: 0.3323\n",
      "Epoch 41/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4826 - accuracy: 0.8926 - val_loss: 2.6372 - val_accuracy: 0.3345\n",
      "Epoch 42/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4769 - accuracy: 0.8925 - val_loss: 2.6578 - val_accuracy: 0.3269\n",
      "Epoch 43/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4664 - accuracy: 0.8967 - val_loss: 2.6841 - val_accuracy: 0.3295\n",
      "Epoch 44/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4524 - accuracy: 0.9035 - val_loss: 2.7061 - val_accuracy: 0.3243\n",
      "Epoch 45/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4524 - accuracy: 0.8988 - val_loss: 2.7278 - val_accuracy: 0.3226\n",
      "Epoch 46/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4386 - accuracy: 0.9087 - val_loss: 2.7612 - val_accuracy: 0.3218\n",
      "Epoch 47/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4305 - accuracy: 0.9100 - val_loss: 2.7843 - val_accuracy: 0.3237\n",
      "Epoch 48/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4214 - accuracy: 0.9137 - val_loss: 2.8257 - val_accuracy: 0.3207\n",
      "Epoch 49/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4172 - accuracy: 0.9138 - val_loss: 2.8432 - val_accuracy: 0.3276\n",
      "Epoch 50/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4083 - accuracy: 0.9186 - val_loss: 2.8243 - val_accuracy: 0.3233\n",
      "Epoch 51/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3924 - accuracy: 0.9274 - val_loss: 2.8680 - val_accuracy: 0.3225\n",
      "Epoch 52/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3906 - accuracy: 0.9256 - val_loss: 2.8840 - val_accuracy: 0.3193\n",
      "Epoch 53/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3837 - accuracy: 0.9295 - val_loss: 2.9483 - val_accuracy: 0.3146\n",
      "Epoch 54/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3775 - accuracy: 0.9309 - val_loss: 2.9470 - val_accuracy: 0.3202\n",
      "Epoch 55/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3693 - accuracy: 0.9331 - val_loss: 2.9621 - val_accuracy: 0.3162\n",
      "Epoch 56/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3620 - accuracy: 0.9368 - val_loss: 2.9650 - val_accuracy: 0.3201\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3544 - accuracy: 0.9373 - val_loss: 2.9918 - val_accuracy: 0.3196\n",
      "Epoch 58/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3456 - accuracy: 0.9433 - val_loss: 3.0287 - val_accuracy: 0.3164\n",
      "Epoch 59/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3468 - accuracy: 0.9394 - val_loss: 3.0735 - val_accuracy: 0.3170\n",
      "Epoch 60/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3357 - accuracy: 0.9448 - val_loss: 3.0676 - val_accuracy: 0.3166\n",
      "Epoch 61/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3269 - accuracy: 0.9488 - val_loss: 3.0990 - val_accuracy: 0.3134\n",
      "Epoch 62/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3212 - accuracy: 0.9515 - val_loss: 3.1150 - val_accuracy: 0.3156\n",
      "Epoch 63/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3132 - accuracy: 0.9532 - val_loss: 3.1322 - val_accuracy: 0.3120\n",
      "Epoch 64/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3117 - accuracy: 0.9531 - val_loss: 3.1479 - val_accuracy: 0.3139\n",
      "Epoch 65/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3061 - accuracy: 0.9550 - val_loss: 3.2177 - val_accuracy: 0.3098\n",
      "Epoch 66/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3005 - accuracy: 0.9552 - val_loss: 3.1995 - val_accuracy: 0.3144\n",
      "Epoch 67/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2953 - accuracy: 0.9580 - val_loss: 3.2004 - val_accuracy: 0.3178\n",
      "Epoch 68/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2865 - accuracy: 0.9621 - val_loss: 3.2487 - val_accuracy: 0.3133\n",
      "Epoch 69/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2800 - accuracy: 0.9649 - val_loss: 3.2567 - val_accuracy: 0.3141\n",
      "Epoch 70/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2735 - accuracy: 0.9682 - val_loss: 3.2992 - val_accuracy: 0.3178\n",
      "Epoch 71/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2735 - accuracy: 0.9653 - val_loss: 3.3029 - val_accuracy: 0.3132\n",
      "Epoch 72/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2659 - accuracy: 0.9684 - val_loss: 3.3348 - val_accuracy: 0.3139\n",
      "Epoch 73/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2642 - accuracy: 0.9688 - val_loss: 3.3504 - val_accuracy: 0.3128\n",
      "Epoch 74/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2575 - accuracy: 0.9710 - val_loss: 3.3781 - val_accuracy: 0.3116\n",
      "Epoch 75/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2524 - accuracy: 0.9724 - val_loss: 3.4029 - val_accuracy: 0.3103\n",
      "Epoch 76/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2467 - accuracy: 0.9738 - val_loss: 3.4490 - val_accuracy: 0.3100\n",
      "Epoch 77/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2436 - accuracy: 0.9741 - val_loss: 3.4632 - val_accuracy: 0.3117\n",
      "Epoch 78/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2391 - accuracy: 0.9771 - val_loss: 3.4665 - val_accuracy: 0.3122\n",
      "Epoch 79/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2324 - accuracy: 0.9778 - val_loss: 3.4752 - val_accuracy: 0.3120\n",
      "Epoch 80/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2322 - accuracy: 0.9763 - val_loss: 3.5107 - val_accuracy: 0.3099\n",
      "Epoch 81/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2253 - accuracy: 0.9807 - val_loss: 3.5451 - val_accuracy: 0.3046\n",
      "Epoch 82/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2218 - accuracy: 0.9805 - val_loss: 3.5430 - val_accuracy: 0.3093\n",
      "Epoch 83/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2175 - accuracy: 0.9812 - val_loss: 3.5824 - val_accuracy: 0.3104\n",
      "Epoch 84/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2150 - accuracy: 0.9827 - val_loss: 3.5866 - val_accuracy: 0.3123\n",
      "Epoch 85/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2084 - accuracy: 0.9838 - val_loss: 3.6269 - val_accuracy: 0.3055\n",
      "Epoch 86/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2067 - accuracy: 0.9834 - val_loss: 3.6585 - val_accuracy: 0.3072\n",
      "Epoch 87/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2009 - accuracy: 0.9856 - val_loss: 3.6943 - val_accuracy: 0.3068\n",
      "Epoch 88/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2039 - accuracy: 0.9829 - val_loss: 3.6760 - val_accuracy: 0.3078\n",
      "Epoch 89/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1967 - accuracy: 0.9855 - val_loss: 3.7065 - val_accuracy: 0.3078\n",
      "Epoch 90/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1928 - accuracy: 0.9864 - val_loss: 3.7230 - val_accuracy: 0.3093\n",
      "Epoch 91/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1879 - accuracy: 0.9878 - val_loss: 3.7359 - val_accuracy: 0.3077\n",
      "Epoch 92/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1848 - accuracy: 0.9884 - val_loss: 3.7606 - val_accuracy: 0.3061\n",
      "Epoch 93/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1814 - accuracy: 0.9889 - val_loss: 3.7941 - val_accuracy: 0.3023\n",
      "Epoch 94/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1760 - accuracy: 0.9902 - val_loss: 3.8224 - val_accuracy: 0.3087\n",
      "Epoch 95/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1742 - accuracy: 0.9909 - val_loss: 3.8245 - val_accuracy: 0.3055\n",
      "Epoch 96/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1714 - accuracy: 0.9916 - val_loss: 3.8481 - val_accuracy: 0.3074\n",
      "Epoch 97/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1686 - accuracy: 0.9916 - val_loss: 3.8727 - val_accuracy: 0.3048\n",
      "Epoch 98/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1682 - accuracy: 0.9906 - val_loss: 3.9072 - val_accuracy: 0.3077\n",
      "Epoch 99/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1628 - accuracy: 0.9920 - val_loss: 3.9241 - val_accuracy: 0.3083\n",
      "Epoch 100/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1606 - accuracy: 0.9924 - val_loss: 3.9364 - val_accuracy: 0.3011\n",
      "Epoch 101/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1581 - accuracy: 0.9922 - val_loss: 3.9803 - val_accuracy: 0.3002\n",
      "Epoch 102/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1537 - accuracy: 0.9938 - val_loss: 3.9902 - val_accuracy: 0.3041\n",
      "Epoch 103/200\n",
      " 71/100 [====================>.........] - ETA: 0s - loss: 0.1457 - accuracy: 0.9952"
     ]
    }
   ],
   "source": [
    "model_name = time.strftime('CIFAR10_KERAS_HWNET%Y%m%d%H%M%S')\n",
    "\n",
    "callback_list = [\n",
    "#     ReduceLROnPlateau(monitor='loss', factor=0.7,  patience=8, min_lr=1e-7, verbose=True),\n",
    "    EarlyStopping(monitor='loss', patience=32),\n",
    "    ModelCheckpoint('models/%s_best.h5'%model_name, monitor='loss', save_best_only=True, verbose=False),\n",
    "    TensorBoard(log_dir='./Log/%s'%model_name)\n",
    "]\n",
    "\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=500, validation_data=(x_test, y_test), callbacks=callback_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
