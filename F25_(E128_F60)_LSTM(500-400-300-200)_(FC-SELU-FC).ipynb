{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62ecd26",
   "metadata": {},
   "source": [
    "Reference\n",
    "* https://www.kaggle.com/hirayukis/pytorch-lstm-cv-0-1942-lb-0-193\n",
    "  * 242,5729\n",
    "* https://www.kaggle.com/dienhoa/ventillator-fastai-lb-0-168-no-kfolds-no-blend?scriptVersionId=78176083\n",
    "  * 1051,2501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb18dba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:34.441284Z",
     "iopub.status.busy": "2021-10-30T16:13:34.440286Z",
     "iopub.status.idle": "2021-10-30T16:13:36.209240Z",
     "shell.execute_reply": "2021-10-30T16:13:36.209240Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import argparse\n",
    "from fastai.layers import swish\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "from fastai.callback.schedule import Learner\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.losses import L1LossFlat\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.callback.tracker import ReduceLROnPlateau, SaveModelCallback\n",
    "\n",
    "from HW_base import evaluate_build, focus_build\n",
    "from HW_torch import dataLoads_build, net_parameter_count, hw_layer\n",
    "from HW_torch import torch_valid, torch_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be584b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:36.211234Z",
     "iopub.status.busy": "2021-10-30T16:13:36.211234Z",
     "iopub.status.idle": "2021-10-30T16:13:36.225215Z",
     "shell.execute_reply": "2021-10-30T16:13:36.225215Z"
    }
   },
   "outputs": [],
   "source": [
    "fname = 'F25_(E128_F60)_LSTM(500-400-300-200)_(FC-SELU-FC)'\n",
    "evaluate_num = 128\n",
    "focus_min = 0.6\n",
    "epoch_num = 200\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d55110b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:36.231199Z",
     "iopub.status.busy": "2021-10-30T16:13:36.230201Z",
     "iopub.status.idle": "2021-10-30T16:13:36.241180Z",
     "shell.execute_reply": "2021-10-30T16:13:36.241180Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, evaluate_focus_list):\n",
    "        super().__init__()\n",
    "        hidden = [500, 400, 300, 200]\n",
    "        self.hw_layer = hw_layer(evaluate_focus_list)\n",
    "        self.lstm1 = nn.LSTM(self.hw_layer.channels, hidden[0],\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(2 * hidden[0], hidden[1],\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.lstm3 = nn.LSTM(2 * hidden[1], hidden[2],\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.lstm4 = nn.LSTM(2 * hidden[2], hidden[3],\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(2 * hidden[3], 50)\n",
    "        self.selu = nn.SELU()\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "        self._reinitialize()\n",
    "\n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'lstm' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "            elif 'fc' in name:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'bias' in name:\n",
    "                    p.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hw_layer(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.selu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b48cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:36.243175Z",
     "iopub.status.busy": "2021-10-30T16:13:36.243175Z",
     "iopub.status.idle": "2021-10-30T16:13:40.477893Z",
     "shell.execute_reply": "2021-10-30T16:13:40.477893Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train_df = pd.read_csv('./Database/train.csv')\n",
    "data_test_df = pd.read_csv('./Database/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1456ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "    df['cross']= df['u_in']*df['u_out']\n",
    "    df['cross2']= df['time_step']*df['u_out']\n",
    "    \n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "    df['one'] = 1\n",
    "    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n",
    "    df['u_in_cummean'] =df['u_in_cumsum'] /df['count']\n",
    "    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n",
    "    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n",
    "    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n",
    "    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n",
    "    df['u_in_lag'] = df['u_in'].shift(1).fillna(0)\n",
    "    df['u_in_lag'] = df['u_in_lag']*df['breath_id_lagsame']\n",
    "    df['u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n",
    "    df['u_in_lag2'] = df['u_in_lag2']*df['breath_id_lag2same']\n",
    "    df['u_out_lag2'] = df['u_out'].shift(2).fillna(0)\n",
    "    df['u_out_lag2'] = df['u_out_lag2']*df['breath_id_lag2same']\n",
    "    #df['u_in_lag'] = df['u_in'].shift(2).fillna(0)\n",
    "    \n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df['RC'] = df['R']+df['C']\n",
    "    df = pd.get_dummies(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54876234",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_df = add_features(data_train_df)\n",
    "data_test_df = add_features(data_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f896618a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.479887Z",
     "iopub.status.busy": "2021-10-30T16:13:40.479887Z",
     "iopub.status.idle": "2021-10-30T16:13:40.492874Z",
     "shell.execute_reply": "2021-10-30T16:13:40.493873Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_columns = ['pressure','id', 'breath_id','one','count','breath_id_lag','breath_id_lag2','breath_id_lagsame','breath_id_lag2same','u_out_lag2']\n",
    "x_columns = [col for col in data_train_df.columns if col not in drop_columns]\n",
    "y_columns = ['pressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d17a06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.496865Z",
     "iopub.status.busy": "2021-10-30T16:13:40.496865Z",
     "iopub.status.idle": "2021-10-30T16:13:40.954666Z",
     "shell.execute_reply": "2021-10-30T16:13:40.954666Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = data_train_df[x_columns].values.astype(np.float32)\n",
    "data_train = data_train.reshape(-1, 80, data_train.shape[-1])\n",
    "\n",
    "target_train = data_train_df[y_columns].values.astype(np.float32)\n",
    "target_train = target_train.reshape(-1, 80, target_train.shape[-1])\n",
    "\n",
    "data_test = data_test_df[x_columns].values.astype(np.float32)\n",
    "data_test = data_test.reshape(-1, 80, data_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e0e206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75450, 80, 25)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab5d58bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.958655Z",
     "iopub.status.busy": "2021-10-30T16:13:40.958655Z",
     "iopub.status.idle": "2021-10-30T16:13:40.970637Z",
     "shell.execute_reply": "2021-10-30T16:13:40.970637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60360 15090\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(121212)\n",
    "data_idx = np.arange(len(data_train))\n",
    "np.random.shuffle(data_idx)\n",
    "\n",
    "train_index = data_idx[:int(len(data_idx)*0.8)]\n",
    "valid_index = data_idx[int(len(data_idx)*0.8):]\n",
    "\n",
    "print(len(train_index), len(valid_index))\n",
    "\n",
    "x_train, y_train = data_train[train_index], target_train[train_index]\n",
    "x_valid, y_valid = data_train[valid_index], target_train[valid_index]\n",
    "x_test = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7667354f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:41.083361Z",
     "iopub.status.busy": "2021-10-30T16:13:41.083361Z",
     "iopub.status.idle": "2021-10-30T16:13:41.097342Z",
     "shell.execute_reply": "2021-10-30T16:13:41.098340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_train_df\n",
    "del data_test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b53cfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluate_num: 127,focus:0.6000: 127it [00:00, 342.92it/s]\n",
      "evaluate_num:  99,focus:0.6000: 99it [00:00, 285.62it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, 2005.40it/s]\n",
      "evaluate_num: 127,focus:0.6000: 127it [00:00, 164.22it/s]\n",
      "evaluate_num:  57,focus:0.6000: 57it [00:00, 501.34it/s]\n",
      "evaluate_num:  80,focus:0.6000: 80it [00:00, 553.20it/s]\n",
      "evaluate_num: 128,focus:0.6000: 128it [00:00, 138.89it/s]\n",
      "evaluate_num: 128,focus:0.6000: 128it [00:00, 232.70it/s]\n",
      "evaluate_num:  97,focus:0.6000: 97it [00:00, 279.48it/s]\n",
      "evaluate_num:  95,focus:0.6000: 95it [00:00, 305.42it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate_list = [evaluate_build(x_test[..., i], evaluate_num) for i in range(x_test.shape[-1])]\n",
    "evaluate_focus_list = []\n",
    "for evaluate in evaluate_list:\n",
    "    focus = 1 - (len(evaluate) - 1)/10\n",
    "    if focus < focus_min:\n",
    "        focus = focus_min\n",
    "    evaluate_focus = focus_build(evaluate, focus)\n",
    "    evaluate_focus_list.append(evaluate_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "153da271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:42.373340Z",
     "iopub.status.busy": "2021-10-30T16:13:42.373340Z",
     "iopub.status.idle": "2021-10-30T16:13:42.385326Z",
     "shell.execute_reply": "2021-10-30T16:13:42.386322Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (hw_layer): hw_layer(\n",
      "    (evaluate_list): ModuleList(\n",
      "      (0): Embedding(127, 1)\n",
      "      (1): Embedding(99, 1)\n",
      "      (2): Embedding(2, 1)\n",
      "      (3): Embedding(127, 1)\n",
      "      (4): Embedding(57, 1)\n",
      "      (5): Embedding(80, 1)\n",
      "      (6): Embedding(128, 1)\n",
      "      (7): Embedding(128, 1)\n",
      "      (8): Embedding(97, 1)\n",
      "      (9): Embedding(95, 1)\n",
      "      (10): Embedding(2, 1)\n",
      "      (11): Embedding(2, 1)\n",
      "      (12): Embedding(2, 1)\n",
      "      (13): Embedding(2, 1)\n",
      "      (14): Embedding(2, 1)\n",
      "      (15): Embedding(2, 1)\n",
      "      (16): Embedding(2, 1)\n",
      "      (17): Embedding(2, 1)\n",
      "      (18): Embedding(2, 1)\n",
      "      (19): Embedding(2, 1)\n",
      "      (20): Embedding(2, 1)\n",
      "      (21): Embedding(2, 1)\n",
      "      (22): Embedding(2, 1)\n",
      "      (23): Embedding(2, 1)\n",
      "      (24): Embedding(2, 1)\n",
      "    )\n",
      "    (focus_list): ModuleList(\n",
      "      (0): Embedding(127, 1)\n",
      "      (1): Embedding(99, 1)\n",
      "      (2): Embedding(2, 1)\n",
      "      (3): Embedding(127, 1)\n",
      "      (4): Embedding(57, 1)\n",
      "      (5): Embedding(80, 1)\n",
      "      (6): Embedding(128, 1)\n",
      "      (7): Embedding(128, 1)\n",
      "      (8): Embedding(97, 1)\n",
      "      (9): Embedding(95, 1)\n",
      "      (10): Embedding(2, 1)\n",
      "      (11): Embedding(2, 1)\n",
      "      (12): Embedding(2, 1)\n",
      "      (13): Embedding(2, 1)\n",
      "      (14): Embedding(2, 1)\n",
      "      (15): Embedding(2, 1)\n",
      "      (16): Embedding(2, 1)\n",
      "      (17): Embedding(2, 1)\n",
      "      (18): Embedding(2, 1)\n",
      "      (19): Embedding(2, 1)\n",
      "      (20): Embedding(2, 1)\n",
      "      (21): Embedding(2, 1)\n",
      "      (22): Embedding(2, 1)\n",
      "      (23): Embedding(2, 1)\n",
      "      (24): Embedding(2, 1)\n",
      "    )\n",
      "  )\n",
      "  (lstm1): LSTM(970, 500, batch_first=True, bidirectional=True)\n",
      "  (lstm2): LSTM(1000, 400, batch_first=True, bidirectional=True)\n",
      "  (lstm3): LSTM(800, 300, batch_first=True, bidirectional=True)\n",
      "  (lstm4): LSTM(600, 200, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=400, out_features=50, bias=True)\n",
      "  (selu): SELU()\n",
      "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n",
      "14322501 1940\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(evaluate_focus_list)\n",
    "print(model)\n",
    "\n",
    "train_parameter_num, freeze_parameter_num = net_parameter_count(model)\n",
    "print(train_parameter_num, freeze_parameter_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29404531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_submission(epoch_num, batch_size):\n",
    "    dataLoads = dataLoads_build(x_train, y_train, x_valid, y_valid, batch_size)\n",
    "    learn = Learner(dataLoads, model, loss_func=L1LossFlat())\n",
    "    learn.lr_find()\n",
    "    learn.fit_one_cycle(epoch_num, lr_max=2e-3, cbs=[ReduceLROnPlateau(monitor='valid_loss', min_delta=0.5, patience=10),\n",
    "                                                     SaveModelCallback(monitor='valid_loss', fname=f'{fname}_B{batch_size}_best')])\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    state_dict = torch.load(f'models/{fname}_B{batch_size}_best.pth')\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    loss = torch_valid([model.to(device)], L1LossFlat(), (x_train, y_train),  batch_size, to_device=device)\n",
    "    valid_loss = torch_valid([model.to(device)], L1LossFlat(), (x_valid, y_valid),  batch_size, to_device=device)\n",
    "\n",
    "    print(loss, valid_loss)\n",
    "\n",
    "    predict = torch_predict([model.to(device)], x_test, batch_size, to_device=device)\n",
    "    predict = np.reshape(predict, (-1))\n",
    "\n",
    "    df = pd.read_csv('Database/sample_submission.csv', index_col=0)\n",
    "    df['pressure'] = predict\n",
    "\n",
    "    df.to_csv(f'Submission/{fname}_B{batch_size}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d97e42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.028761</td>\n",
       "      <td>0.991920</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.841693</td>\n",
       "      <td>0.880962</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.771433</td>\n",
       "      <td>0.748813</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.729208</td>\n",
       "      <td>0.708353</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.674281</td>\n",
       "      <td>0.679316</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.653300</td>\n",
       "      <td>0.662025</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.568396</td>\n",
       "      <td>0.564543</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.506440</td>\n",
       "      <td>0.510566</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.476165</td>\n",
       "      <td>0.480980</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.486755</td>\n",
       "      <td>0.539107</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.431315</td>\n",
       "      <td>0.439543</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.421767</td>\n",
       "      <td>0.439621</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.409334</td>\n",
       "      <td>0.467617</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.402990</td>\n",
       "      <td>0.409512</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.387655</td>\n",
       "      <td>0.426407</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.375227</td>\n",
       "      <td>0.408847</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.365214</td>\n",
       "      <td>0.373111</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.374930</td>\n",
       "      <td>0.381434</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.357221</td>\n",
       "      <td>0.359298</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.343796</td>\n",
       "      <td>0.361337</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.362986</td>\n",
       "      <td>0.359694</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.361530</td>\n",
       "      <td>0.335425</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.348313</td>\n",
       "      <td>0.336223</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.329667</td>\n",
       "      <td>0.322203</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.317901</td>\n",
       "      <td>0.322376</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.308043</td>\n",
       "      <td>0.306955</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.304356</td>\n",
       "      <td>0.368123</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.293737</td>\n",
       "      <td>0.307370</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.291979</td>\n",
       "      <td>0.289858</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.291236</td>\n",
       "      <td>0.290077</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.300118</td>\n",
       "      <td>0.320641</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.277820</td>\n",
       "      <td>0.311748</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.276869</td>\n",
       "      <td>0.278698</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.276244</td>\n",
       "      <td>0.303431</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.263458</td>\n",
       "      <td>0.268942</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.288712</td>\n",
       "      <td>0.299326</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.265216</td>\n",
       "      <td>0.271109</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.269952</td>\n",
       "      <td>0.266966</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.256187</td>\n",
       "      <td>0.453567</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.245850</td>\n",
       "      <td>0.262640</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.253798</td>\n",
       "      <td>0.274826</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.246398</td>\n",
       "      <td>0.267604</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.234387</td>\n",
       "      <td>0.258732</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.237746</td>\n",
       "      <td>0.271432</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.246569</td>\n",
       "      <td>0.256133</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.221698</td>\n",
       "      <td>0.251819</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.221517</td>\n",
       "      <td>0.239292</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.229528</td>\n",
       "      <td>0.240788</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.216613</td>\n",
       "      <td>0.240483</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.227551</td>\n",
       "      <td>0.246591</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.215448</td>\n",
       "      <td>0.242459</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.210408</td>\n",
       "      <td>0.231531</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.203569</td>\n",
       "      <td>0.222896</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.200259</td>\n",
       "      <td>0.233129</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.198378</td>\n",
       "      <td>0.227822</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.216036</td>\n",
       "      <td>0.234426</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.195162</td>\n",
       "      <td>0.251776</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.216245</td>\n",
       "      <td>0.252141</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.191963</td>\n",
       "      <td>0.228023</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.183359</td>\n",
       "      <td>0.217979</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.189199</td>\n",
       "      <td>0.220140</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.187022</td>\n",
       "      <td>0.216568</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.180204</td>\n",
       "      <td>0.218722</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.211235</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.173339</td>\n",
       "      <td>0.214176</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.179945</td>\n",
       "      <td>0.220103</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.180842</td>\n",
       "      <td>0.249087</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.173247</td>\n",
       "      <td>0.210925</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.166170</td>\n",
       "      <td>0.207863</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.164160</td>\n",
       "      <td>0.208574</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.162999</td>\n",
       "      <td>0.205949</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.159768</td>\n",
       "      <td>0.202781</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.163530</td>\n",
       "      <td>0.211160</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.156115</td>\n",
       "      <td>0.199760</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.156663</td>\n",
       "      <td>0.206933</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.151409</td>\n",
       "      <td>0.200014</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.150706</td>\n",
       "      <td>0.198813</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.149724</td>\n",
       "      <td>0.200152</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.152687</td>\n",
       "      <td>0.204782</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.146302</td>\n",
       "      <td>0.199149</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.147334</td>\n",
       "      <td>0.198388</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.145072</td>\n",
       "      <td>0.201302</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.142226</td>\n",
       "      <td>0.211393</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.141843</td>\n",
       "      <td>0.195710</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.140277</td>\n",
       "      <td>0.198755</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.139299</td>\n",
       "      <td>0.200919</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.136082</td>\n",
       "      <td>0.194575</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.134519</td>\n",
       "      <td>0.192255</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.134494</td>\n",
       "      <td>0.189792</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.131331</td>\n",
       "      <td>0.192285</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.129505</td>\n",
       "      <td>0.192305</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.128253</td>\n",
       "      <td>0.191077</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.127149</td>\n",
       "      <td>0.193330</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.126002</td>\n",
       "      <td>0.189566</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.123891</td>\n",
       "      <td>0.190599</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.124264</td>\n",
       "      <td>0.191980</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.127230</td>\n",
       "      <td>0.199160</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.125899</td>\n",
       "      <td>0.193473</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.122090</td>\n",
       "      <td>0.190717</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.122071</td>\n",
       "      <td>0.192663</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.117676</td>\n",
       "      <td>0.190497</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.118137</td>\n",
       "      <td>0.189364</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.194694</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.115029</td>\n",
       "      <td>0.188957</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.113211</td>\n",
       "      <td>0.188788</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.111994</td>\n",
       "      <td>0.189064</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.110495</td>\n",
       "      <td>0.188813</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.110371</td>\n",
       "      <td>0.188689</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.108139</td>\n",
       "      <td>0.189044</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.106265</td>\n",
       "      <td>0.188510</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.105853</td>\n",
       "      <td>0.187043</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.104793</td>\n",
       "      <td>0.188039</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.103274</td>\n",
       "      <td>0.187746</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.103682</td>\n",
       "      <td>0.189418</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.100871</td>\n",
       "      <td>0.189041</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>0.187838</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.101736</td>\n",
       "      <td>0.189925</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.098475</td>\n",
       "      <td>0.185963</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.096890</td>\n",
       "      <td>0.185635</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.094799</td>\n",
       "      <td>0.186776</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.094904</td>\n",
       "      <td>0.185551</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.092651</td>\n",
       "      <td>0.187142</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.091384</td>\n",
       "      <td>0.186666</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.100587</td>\n",
       "      <td>0.191736</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.090262</td>\n",
       "      <td>0.186446</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.088326</td>\n",
       "      <td>0.187865</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.086843</td>\n",
       "      <td>0.185602</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.086714</td>\n",
       "      <td>0.186014</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.084139</td>\n",
       "      <td>0.184723</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.083126</td>\n",
       "      <td>0.185521</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.082666</td>\n",
       "      <td>0.186989</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.080984</td>\n",
       "      <td>0.185791</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.080066</td>\n",
       "      <td>0.185194</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.078165</td>\n",
       "      <td>0.185341</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.077814</td>\n",
       "      <td>0.185485</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.076552</td>\n",
       "      <td>0.185198</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.075390</td>\n",
       "      <td>0.185367</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.074259</td>\n",
       "      <td>0.185170</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.073731</td>\n",
       "      <td>0.185542</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.072841</td>\n",
       "      <td>0.184892</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.071683</td>\n",
       "      <td>0.185101</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.070755</td>\n",
       "      <td>0.184709</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.069743</td>\n",
       "      <td>0.184639</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.069201</td>\n",
       "      <td>0.184412</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.067722</td>\n",
       "      <td>0.184632</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.066856</td>\n",
       "      <td>0.184746</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.065411</td>\n",
       "      <td>0.184950</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.064844</td>\n",
       "      <td>0.184379</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.063569</td>\n",
       "      <td>0.184766</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.063740</td>\n",
       "      <td>0.184491</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.062115</td>\n",
       "      <td>0.184620</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.061649</td>\n",
       "      <td>0.184758</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.060927</td>\n",
       "      <td>0.184616</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.060074</td>\n",
       "      <td>0.184661</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.058902</td>\n",
       "      <td>0.184870</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.057986</td>\n",
       "      <td>0.184779</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.058120</td>\n",
       "      <td>0.185417</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.056485</td>\n",
       "      <td>0.184943</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.055938</td>\n",
       "      <td>0.184834</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.055535</td>\n",
       "      <td>0.184803</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.054487</td>\n",
       "      <td>0.184795</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.054084</td>\n",
       "      <td>0.184749</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.053259</td>\n",
       "      <td>0.185149</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.052735</td>\n",
       "      <td>0.185155</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.052061</td>\n",
       "      <td>0.185159</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.051105</td>\n",
       "      <td>0.185215</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.050857</td>\n",
       "      <td>0.184962</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.050389</td>\n",
       "      <td>0.185227</td>\n",
       "      <td>01:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.049690</td>\n",
       "      <td>0.185129</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.048978</td>\n",
       "      <td>0.185250</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.048549</td>\n",
       "      <td>0.185250</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.048273</td>\n",
       "      <td>0.185477</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.048098</td>\n",
       "      <td>0.185435</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.046981</td>\n",
       "      <td>0.185553</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.046761</td>\n",
       "      <td>0.185541</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.046493</td>\n",
       "      <td>0.185815</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.046142</td>\n",
       "      <td>0.185744</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.045675</td>\n",
       "      <td>0.185839</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.045604</td>\n",
       "      <td>0.185779</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.045103</td>\n",
       "      <td>0.185809</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.044772</td>\n",
       "      <td>0.185812</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.044348</td>\n",
       "      <td>0.185942</td>\n",
       "      <td>01:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.044229</td>\n",
       "      <td>0.185887</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.043684</td>\n",
       "      <td>0.185959</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.043302</td>\n",
       "      <td>0.186015</td>\n",
       "      <td>01:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.043310</td>\n",
       "      <td>0.186060</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.043084</td>\n",
       "      <td>0.186035</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.042861</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.042875</td>\n",
       "      <td>0.186112</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.042602</td>\n",
       "      <td>0.186120</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.042528</td>\n",
       "      <td>0.186144</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.042438</td>\n",
       "      <td>0.186180</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.042342</td>\n",
       "      <td>0.186172</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.041979</td>\n",
       "      <td>0.186190</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.042252</td>\n",
       "      <td>0.186187</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.042253</td>\n",
       "      <td>0.186198</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.042062</td>\n",
       "      <td>0.186197</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.041984</td>\n",
       "      <td>0.186203</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.042135</td>\n",
       "      <td>0.186204</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.041758</td>\n",
       "      <td>0.186204</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.9919195175170898.\n",
      "Better model found at epoch 1 with valid_loss value: 0.8809615969657898.\n",
      "Better model found at epoch 2 with valid_loss value: 0.7488126158714294.\n",
      "Better model found at epoch 3 with valid_loss value: 0.7083525061607361.\n",
      "Better model found at epoch 4 with valid_loss value: 0.6793163418769836.\n",
      "Better model found at epoch 5 with valid_loss value: 0.6620248556137085.\n",
      "Better model found at epoch 6 with valid_loss value: 0.564542829990387.\n",
      "Better model found at epoch 7 with valid_loss value: 0.5105659365653992.\n",
      "Better model found at epoch 8 with valid_loss value: 0.48098012804985046.\n",
      "Better model found at epoch 10 with valid_loss value: 0.4395429193973541.\n",
      "Better model found at epoch 13 with valid_loss value: 0.40951162576675415.\n",
      "Better model found at epoch 15 with valid_loss value: 0.40884730219841003.\n",
      "Better model found at epoch 16 with valid_loss value: 0.37311089038848877.\n",
      "Better model found at epoch 18 with valid_loss value: 0.35929808020591736.\n",
      "Epoch 18: reducing lr to 6.865075718286959e-05\n",
      "Better model found at epoch 21 with valid_loss value: 0.335425466299057.\n",
      "Better model found at epoch 23 with valid_loss value: 0.3222030997276306.\n",
      "Better model found at epoch 25 with valid_loss value: 0.306954950094223.\n",
      "Better model found at epoch 28 with valid_loss value: 0.28985798358917236.\n",
      "Epoch 28: reducing lr to 0.00012786456073794083\n",
      "Better model found at epoch 32 with valid_loss value: 0.27869847416877747.\n",
      "Better model found at epoch 34 with valid_loss value: 0.26894238591194153.\n",
      "Better model found at epoch 37 with valid_loss value: 0.26696574687957764.\n",
      "Epoch 38: reducing lr to 0.00017796290591172087\n",
      "Better model found at epoch 39 with valid_loss value: 0.2626403272151947.\n",
      "Better model found at epoch 42 with valid_loss value: 0.2587318420410156.\n",
      "Better model found at epoch 44 with valid_loss value: 0.25613340735435486.\n",
      "Better model found at epoch 45 with valid_loss value: 0.25181910395622253.\n",
      "Better model found at epoch 46 with valid_loss value: 0.23929238319396973.\n",
      "Epoch 48: reducing lr to 0.00019980993819022062\n",
      "Better model found at epoch 51 with valid_loss value: 0.2315308153629303.\n",
      "Better model found at epoch 52 with valid_loss value: 0.2228960245847702.\n",
      "Epoch 58: reducing lr to 0.00019822939170434112\n",
      "Better model found at epoch 59 with valid_loss value: 0.21797935664653778.\n",
      "Better model found at epoch 61 with valid_loss value: 0.21656760573387146.\n",
      "Better model found at epoch 63 with valid_loss value: 0.21123452484607697.\n",
      "Better model found at epoch 67 with valid_loss value: 0.2109253853559494.\n",
      "Better model found at epoch 68 with valid_loss value: 0.20786310732364655.\n",
      "Epoch 68: reducing lr to 0.00019218773766199265\n",
      "Better model found at epoch 70 with valid_loss value: 0.20594945549964905.\n",
      "Better model found at epoch 71 with valid_loss value: 0.202781081199646.\n",
      "Better model found at epoch 73 with valid_loss value: 0.19975963234901428.\n",
      "Better model found at epoch 76 with valid_loss value: 0.19881340861320496.\n",
      "Epoch 78: reducing lr to 0.00018211707775273614\n",
      "Better model found at epoch 80 with valid_loss value: 0.19838835299015045.\n",
      "Better model found at epoch 83 with valid_loss value: 0.19570976495742798.\n",
      "Better model found at epoch 86 with valid_loss value: 0.19457466900348663.\n",
      "Better model found at epoch 87 with valid_loss value: 0.19225454330444336.\n",
      "Better model found at epoch 88 with valid_loss value: 0.18979161977767944.\n",
      "Epoch 88: reducing lr to 0.0001684575602740172\n",
      "Better model found at epoch 93 with valid_loss value: 0.18956618010997772.\n",
      "Epoch 98: reducing lr to 0.00015180614962432177\n",
      "Better model found at epoch 101 with valid_loss value: 0.18936386704444885.\n",
      "Better model found at epoch 103 with valid_loss value: 0.188956618309021.\n",
      "Better model found at epoch 104 with valid_loss value: 0.18878836929798126.\n",
      "Better model found at epoch 107 with valid_loss value: 0.18868911266326904.\n",
      "Epoch 108: reducing lr to 0.00013289060359938506\n",
      "Better model found at epoch 109 with valid_loss value: 0.1885104477405548.\n",
      "Better model found at epoch 110 with valid_loss value: 0.1870434731245041.\n",
      "Better model found at epoch 117 with valid_loss value: 0.1859627664089203.\n",
      "Better model found at epoch 118 with valid_loss value: 0.1856347769498825.\n",
      "Epoch 118: reducing lr to 0.00011253763225430578\n",
      "Better model found at epoch 120 with valid_loss value: 0.1855507344007492.\n",
      "Better model found at epoch 128 with valid_loss value: 0.18472321331501007.\n",
      "Epoch 128: reducing lr to 9.163675931712789e-05\n",
      "Epoch 138: reducing lr to 7.110143450173828e-05\n",
      "Better model found at epoch 141 with valid_loss value: 0.18470893800258636.\n",
      "Better model found at epoch 142 with valid_loss value: 0.18463918566703796.\n",
      "Better model found at epoch 143 with valid_loss value: 0.1844116449356079.\n",
      "Better model found at epoch 147 with valid_loss value: 0.18437857925891876.\n",
      "Epoch 148: reducing lr to 5.1829159224107296e-05\n",
      "Epoch 158: reducing lr to 3.466221011718213e-05\n",
      "Epoch 168: reducing lr to 2.035089572856364e-05\n",
      "Epoch 178: reducing lr to 9.520680660126497e-06\n",
      "Epoch 188: reducing lr to 2.6448779281701764e-06\n",
      "Epoch 198: reducing lr to 2.400399908594579e-08\n",
      "0.0630381800456355 0.18437169896845787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prodict: 100% 503/503 [00:19<00:00, 25.42it/s]\n",
      "C:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_submission(epoch_num, batch_size)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9cf96c7db471cf61b133b0e4e3b2523172ebb61bf8cc081d235291383382076"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
