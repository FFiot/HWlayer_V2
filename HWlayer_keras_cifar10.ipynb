{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfe55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n",
    "from tensorflow.keras.layers import Softmax, Reshape\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.metrics import AUC, BinaryAccuracy, Accuracy, Recall, Precision\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, LearningRateScheduler, ReduceLROnPlateau, Callback\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from HWlayer_base import evaluate_build, focus_build\n",
    "from HWlayer_keras import HWlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15456512",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train / 255\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "\n",
    "x_test = x_test / 255\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2269fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_num = 8\n",
    "focus = 0.6\n",
    "deepth = 4\n",
    "\n",
    "evaluate_dims = evaluate_num * x_test.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecebaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_build_AveragePooling2D(data, evaluate_num=8, focus=0.8, deepth=3):\n",
    "    output_list = []\n",
    "    x = Input(data.shape[1:])\n",
    "    y_list = [x]\n",
    "    for idx in range(deepth):\n",
    "        y_list += [AveragePooling2D(2)(y_list[-1])]\n",
    "    \n",
    "    model = Model(x, y_list)\n",
    "    data_list = model.predict(data)\n",
    "    \n",
    "    output_list = []\n",
    "    for data in data_list:\n",
    "        print(data.shape)\n",
    "        evaluate_list = [evaluate_build(data[..., i], evaluate_num) for i in range(data.shape[-1])]\n",
    "        evaluate_focus_list = [focus_build(evaluate, focus) for evaluate in evaluate_list]\n",
    "        output_list.append(evaluate_focus_list)\n",
    "        \n",
    "    return output_list\n",
    "\n",
    "evaluate_focus_list = evaluate_build_AveragePooling2D(x_test, evaluate_num, focus, deepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b3b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG5_cfg = [64, 'M', 128, 'M', 256, 'M', 512, 'M', 512, 'M']\n",
    "# VGG5_cfg = [32, 'A', 64, 'A', 128, 'A', 256, 'A', 256, 'A']\n",
    "# VGG16_cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "\n",
    "VGG5_cfg = [16, 'M', 32, 'M', 64, 'M', 128, 'M', 128, 'M']\n",
    "VGG16_cfg = [8, 8, 'A', 16, 16, 'A', 32, 32, 32, 'A', 64, 64, 64, 'A', 64, 64, 64, 'A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf7a03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = Input(shape=((32, 32, 3)))\n",
    "y = x\n",
    "hw_active_dic = {}\n",
    "for evaluate_focus in evaluate_focus_list:\n",
    "    image_size = y.shape[-2]\n",
    "    l = HWlayer(evaluate_focus, name=f'HW_active_{image_size}')(y)\n",
    "    l = K.expand_dims(l, -2)\n",
    "    hw_active_dic[image_size] = l\n",
    "    y = MaxPooling2D(2)(y)\n",
    "\n",
    "y = HWlayer(evaluate_focus_list[0])(x)\n",
    "for cfg in VGG16_cfg:\n",
    "    if cfg == 'M':\n",
    "        y = MaxPooling2D(2, 2)(y)\n",
    "    elif cfg == 'A':\n",
    "        y = AveragePooling2D(2, 2)(y)\n",
    "    else:\n",
    "        y = Conv2D(cfg*evaluate_dims, 3, 1, 'same')(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Activation('relu')(y)\n",
    "        \n",
    "        output_shape = y.shape[1:]\n",
    "        inter_shape = output_shape[:-1] + [cfg, evaluate_dims]\n",
    "        y = Reshape(inter_shape)(y)\n",
    "        # 这里可以增加一个全链接层\n",
    "        # y = Dense(evaluate_dims)(y)\n",
    "        # y = BatchNormalization()(y)\n",
    "        # y = Activation('relu')(y)\n",
    "        # 稀疏激活\n",
    "        image_size = inter_shape[1]\n",
    "        y = y * hw_active_dic[image_size]\n",
    "        y = Reshape(output_shape)(y)\n",
    "\n",
    "y = Flatten()(y)\n",
    "y = Dense(10)(y)\n",
    "y = Softmax(axis=-1)(y)\n",
    "\n",
    "model = Model(x, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b5005",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,  # 将整个数据集的均值设为 0\n",
    "    samplewise_center = False,  # 将每个样本的均值设为 0\n",
    "    featurewise_std_normalization = False,  # 将输入除以整个数据集的标准差\n",
    "    samplewise_std_normalization = False,  # 将输入除以其标准差\n",
    "    zca_whitening = False,  # 运用 ZCA 白化\n",
    "    zca_epsilon = 1e-06,  # ZCA 白化的 epsilon值\n",
    "    rotation_range = 0,  # 随机旋转图像范围 (角度, 0 to 180)\n",
    "    width_shift_range = 0.1,  # 随机水平移动图像 (总宽度的百分比) \n",
    "    height_shift_range = 0.1,  # 随机垂直移动图像 (总高度的百分比)\n",
    "    shear_range = 0.,  # 设置随机裁剪范围\n",
    "    zoom_range = 0.,  # 设置随机放大范围\n",
    "    channel_shift_range = 0.,  # 设置随机通道切换的范围\n",
    "    fill_mode = 'nearest',  # 设置填充输入边界之外的点的模式\n",
    "    cval = 0.,  # 在 fill_mode = \"constant\" 时使用的值\n",
    "    horizontal_flip = True,  # 随机水平翻转图像\n",
    "    vertical_flip = True,  # 随机垂直翻转图像\n",
    "    rescale = None,  # 设置缩放因子 (在其他转换之前使用)\n",
    "    preprocessing_function = None,  # 设置将应用于每一个输入的函数\n",
    "    data_format = None,  # 图像数据格式，\"channels_first\" 或 \"channels_last\" 之一\n",
    "    validation_split = 0.0)  # 保留用于验证的图像比例（严格在 0 和 1之间）\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31554039",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.lr = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs['loss'])\n",
    "        self.lr.append(step_decay(len(self.losses)))\n",
    "\n",
    "# lr_base = 0.001\n",
    "# epochs = 250\n",
    "# lr_power = 0.9\n",
    "# def lr_scheduler(epoch, mode='power_decay'):\n",
    "#     '''if lr_dict.has_key(epoch):\n",
    "#         lr = lr_dict[epoch]\n",
    "#         print 'lr: %f' % lr'''\n",
    " \n",
    "#     if mode is 'power_decay':\n",
    "#         # original lr scheduler\n",
    "#         lr = lr_base * ((1 - float(epoch) / epochs) ** lr_power)\n",
    "#     if mode is 'exp_decay':\n",
    "#         # exponential decay\n",
    "#         lr = (float(lr_base) ** float(lr_power)) ** float(epoch + 1)\n",
    "#     # adam default lr\n",
    "#     if mode is 'adam':\n",
    "#         lr = 0.001\n",
    " \n",
    "#     if mode is 'progressive_drops':\n",
    "#         # drops as progression proceeds, good for sgd\n",
    "#         if epoch > 0.9 * epochs:\n",
    "#             lr = 0.0001\n",
    "#         elif epoch > 0.75 * epochs:\n",
    "#             lr = 0.001\n",
    "#         elif epoch > 0.5 * epochs:\n",
    "#             lr = 0.01\n",
    "#         else:\n",
    "#             lr = 0.1\n",
    " \n",
    "#     print('lr: %f' % lr)\n",
    "#     return lr\n",
    "\n",
    "# callback_list = [LossHistory(), LearningRateScheduler(lr_scheduler),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_base = 0.01\n",
    "epochs = 250\n",
    "lr_power = 0.9\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    lr = lr_base * ((1 - float(epoch) / epochs) ** lr_power)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21177d2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_name = time.strftime('CIFAR10_VGG_KERAS_HWNET%Y%m%d%H%M%S')\n",
    "\n",
    "model.compile(loss=Huber(), optimizer=RMSprop(learning_rate=0.0001, decay=1e-6), metrics=[ 'acc', 'AUC'])\n",
    "\n",
    "callback_list = [\n",
    "    EarlyStopping(monitor='loss', patience=32),\n",
    "    ModelCheckpoint('models/%s_best.h5'%model_name, monitor='loss', save_best_only=True, verbose=False),\n",
    "    TensorBoard(log_dir='./Log/%s'%model_name)\n",
    "]\n",
    "\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=100), epochs=epochs, validation_data=(x_test, y_test), validation_batch_size=100, callbacks=callback_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
