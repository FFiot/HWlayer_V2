{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb18dba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:34.441284Z",
     "iopub.status.busy": "2021-10-30T16:13:34.440286Z",
     "iopub.status.idle": "2021-10-30T16:13:36.209240Z",
     "shell.execute_reply": "2021-10-30T16:13:36.209240Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import argparse\n",
    "from fastai.layers import swish\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from fastai.callback.schedule import Learner\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.losses import L1LossFlat\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.callback.tracker import ReduceLROnPlateau, SaveModelCallback\n",
    "\n",
    "from HW_torch import dataLoads_build, net_parameter_count, hw_layer\n",
    "from HW_base import evaluate_build, focus_build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5be584b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:36.211234Z",
     "iopub.status.busy": "2021-10-30T16:13:36.211234Z",
     "iopub.status.idle": "2021-10-30T16:13:36.225215Z",
     "shell.execute_reply": "2021-10-30T16:13:36.225215Z"
    }
   },
   "outputs": [],
   "source": [
    "fname               = 'F5-E128-F60_Linear-RES-LSTM128x4-FC-SELU-FC'\n",
    "epoch_num_first     = 100\n",
    "batch_size_first    = 100\n",
    "epoch_num_second    = 100\n",
    "batch_size_second   = 400\n",
    "evaluate_num        = 128\n",
    "focus_min           = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d55110b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:36.231199Z",
     "iopub.status.busy": "2021-10-30T16:13:36.230201Z",
     "iopub.status.idle": "2021-10-30T16:13:36.241180Z",
     "shell.execute_reply": "2021-10-30T16:13:36.241180Z"
    }
   },
   "outputs": [],
   "source": [
    "class net_test(torch.nn.Module):\n",
    "    def __init__(self, evaluate_focus_list, **kwargs):\n",
    "        super(net_test, self).__init__()\n",
    "        self.hw_layer = hw_layer(evaluate_focus_list)\n",
    "        self.embedding = torch.nn.Linear(self.hw_layer.channels, 128)\n",
    "\n",
    "        self.lstm1 = torch.nn.LSTM(128, 128, num_layers=1, bias=False, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = torch.nn.LSTM(128*3, 128, num_layers=1, bias=False, bidirectional=True, batch_first=True)\n",
    "        self.lstm3 = torch.nn.LSTM(128*5, 128,  num_layers=1, bias=False, bidirectional=True, batch_first=True)\n",
    "        self.lstm4 = torch.nn.LSTM(128*7, 128,  num_layers=1, bias=False, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(128*8, 32, bias=False)\n",
    "        self.selu = torch.nn.SELU()\n",
    "        self.fc2 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hw_layer(x)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x1, _ = self.lstm1(x)\n",
    "        x = torch.concat((x, x1), dim=-1)\n",
    "\n",
    "        x2, _ = self.lstm2(x)\n",
    "        x = torch.concat((x, x2), dim=-1)\n",
    "\n",
    "        x3, _ = self.lstm3(x)\n",
    "        x = torch.concat((x, x3), dim=-1)\n",
    "\n",
    "        x4, _ = self.lstm4(x)\n",
    "        x = torch.concat((x1, x2, x3, x4), dim=-1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.selu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b48cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:36.243175Z",
     "iopub.status.busy": "2021-10-30T16:13:36.243175Z",
     "iopub.status.idle": "2021-10-30T16:13:40.477893Z",
     "shell.execute_reply": "2021-10-30T16:13:40.477893Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train_df = pd.read_csv('./Database/train.csv')\n",
    "data_test_df = pd.read_csv('./Database/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f896618a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.479887Z",
     "iopub.status.busy": "2021-10-30T16:13:40.479887Z",
     "iopub.status.idle": "2021-10-30T16:13:40.492874Z",
     "shell.execute_reply": "2021-10-30T16:13:40.493873Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_columns = ['pressure','id', 'breath_id','one','count','breath_id_lag','breath_id_lag2','breath_id_lagsame','breath_id_lag2same','u_out_lag2']\n",
    "x_columns = [col for col in data_train_df.columns if col not in drop_columns]\n",
    "y_columns = ['pressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d17a06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.496865Z",
     "iopub.status.busy": "2021-10-30T16:13:40.496865Z",
     "iopub.status.idle": "2021-10-30T16:13:40.954666Z",
     "shell.execute_reply": "2021-10-30T16:13:40.954666Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = data_train_df[x_columns].values.astype(np.float32)\n",
    "data_train = data_train.reshape(-1, 80, data_train.shape[-1])\n",
    "\n",
    "target_train = data_train_df[y_columns].values.astype(np.float32)\n",
    "target_train = target_train.reshape(-1, 80, target_train.shape[-1])\n",
    "\n",
    "data_test = data_test_df[x_columns].values.astype(np.float32)\n",
    "data_test = data_test.reshape(-1, 80, data_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5d58bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.958655Z",
     "iopub.status.busy": "2021-10-30T16:13:40.958655Z",
     "iopub.status.idle": "2021-10-30T16:13:40.970637Z",
     "shell.execute_reply": "2021-10-30T16:13:40.970637Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(121212)\n",
    "data_idx = np.arange(len(data_train))\n",
    "np.random.shuffle(data_idx)\n",
    "\n",
    "train_index = data_idx[:int(len(data_idx)*0.8)]\n",
    "valid_index = data_idx[int(len(data_idx)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916430e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:40.972630Z",
     "iopub.status.busy": "2021-10-30T16:13:40.972630Z",
     "iopub.status.idle": "2021-10-30T16:13:41.034492Z",
     "shell.execute_reply": "2021-10-30T16:13:41.034492Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train = data_train[train_index], target_train[train_index]\n",
    "x_valid, y_valid = data_train[valid_index], target_train[valid_index]\n",
    "x_test = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7667354f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:41.083361Z",
     "iopub.status.busy": "2021-10-30T16:13:41.083361Z",
     "iopub.status.idle": "2021-10-30T16:13:41.097342Z",
     "shell.execute_reply": "2021-10-30T16:13:41.098340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_train_df\n",
    "del data_test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d692dd27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:41.100334Z",
     "iopub.status.busy": "2021-10-30T16:13:41.100334Z",
     "iopub.status.idle": "2021-10-30T16:13:42.369350Z",
     "shell.execute_reply": "2021-10-30T16:13:42.370347Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluate_num:   3,focus:0.8000: 3it [00:00, 3010.27it/s]\n",
      "evaluate_num:   3,focus:0.8000: 3it [00:00, ?it/s]\n",
      "evaluate_num: 127,focus:0.6000: 127it [00:00, 284.88it/s]\n",
      "evaluate_num:  99,focus:0.6000: 99it [00:00, 325.46it/s]\n",
      "evaluate_num:   2,focus:0.9000: 2it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate_list = [evaluate_build(x_test[..., i], evaluate_num) for i in range(x_test.shape[-1])]\n",
    "evaluate_focus_list = []\n",
    "for evaluate in evaluate_list:\n",
    "    focus = 1 - (len(evaluate) - 1)/10\n",
    "    if focus < focus_min:\n",
    "        focus = focus_min\n",
    "    evaluate_focus = focus_build(evaluate, focus)\n",
    "    evaluate_focus_list.append(evaluate_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153da271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:42.373340Z",
     "iopub.status.busy": "2021-10-30T16:13:42.373340Z",
     "iopub.status.idle": "2021-10-30T16:13:42.385326Z",
     "shell.execute_reply": "2021-10-30T16:13:42.386322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_test(\n",
      "  (hw_layer): hw_layer(\n",
      "    (evaluate_list): ModuleList(\n",
      "      (0): Embedding(3, 1)\n",
      "      (1): Embedding(3, 1)\n",
      "      (2): Embedding(127, 1)\n",
      "      (3): Embedding(99, 1)\n",
      "      (4): Embedding(2, 1)\n",
      "    )\n",
      "    (focus_list): ModuleList(\n",
      "      (0): Embedding(3, 1)\n",
      "      (1): Embedding(3, 1)\n",
      "      (2): Embedding(127, 1)\n",
      "      (3): Embedding(99, 1)\n",
      "      (4): Embedding(2, 1)\n",
      "    )\n",
      "  )\n",
      "  (embedding): Linear(in_features=234, out_features=128, bias=True)\n",
      "  (lstm1): LSTM(128, 128, bias=False, batch_first=True, bidirectional=True)\n",
      "  (lstm2): LSTM(384, 128, bias=False, batch_first=True, bidirectional=True)\n",
      "  (lstm3): LSTM(640, 128, bias=False, batch_first=True, bidirectional=True)\n",
      "  (lstm4): LSTM(896, 128, bias=False, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=1024, out_features=32, bias=False)\n",
      "  (selu): SELU()\n",
      "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "2684321 468\n"
     ]
    }
   ],
   "source": [
    "model = net_test(evaluate_focus_list)\n",
    "print(model)\n",
    "\n",
    "train_parameter_num, freeze_parameter_num = net_parameter_count(model)\n",
    "print(train_parameter_num, freeze_parameter_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31c266b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load(f'models/{fname}_best.pth')\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfcce265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:13:42.400288Z",
     "iopub.status.busy": "2021-10-30T16:13:42.399290Z",
     "iopub.status.idle": "2021-10-30T16:36:30.331601Z",
     "shell.execute_reply": "2021-10-30T16:36:30.332599Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.563833</td>\n",
       "      <td>1.409708</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.114924</td>\n",
       "      <td>1.107681</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.957880</td>\n",
       "      <td>0.998081</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.887418</td>\n",
       "      <td>0.890768</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.884775</td>\n",
       "      <td>0.815812</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.729456</td>\n",
       "      <td>0.744565</td>\n",
       "      <td>01:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.660239</td>\n",
       "      <td>0.647317</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.666523</td>\n",
       "      <td>0.740877</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.585852</td>\n",
       "      <td>0.589158</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.612243</td>\n",
       "      <td>0.529354</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.537595</td>\n",
       "      <td>0.547762</td>\n",
       "      <td>01:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.506188</td>\n",
       "      <td>0.521334</td>\n",
       "      <td>01:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.476754</td>\n",
       "      <td>0.461301</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.598362</td>\n",
       "      <td>0.624338</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.471261</td>\n",
       "      <td>0.453425</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.449696</td>\n",
       "      <td>0.433772</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>0.447814</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.411916</td>\n",
       "      <td>0.397490</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.400710</td>\n",
       "      <td>0.424755</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.396770</td>\n",
       "      <td>0.383643</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.374643</td>\n",
       "      <td>0.372930</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.365657</td>\n",
       "      <td>0.384640</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.343875</td>\n",
       "      <td>0.356540</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.347880</td>\n",
       "      <td>0.350975</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.320072</td>\n",
       "      <td>0.326867</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.311870</td>\n",
       "      <td>0.318470</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.308042</td>\n",
       "      <td>0.309778</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.301591</td>\n",
       "      <td>0.297646</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.292457</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.301216</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.292607</td>\n",
       "      <td>0.304472</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.283514</td>\n",
       "      <td>0.286769</td>\n",
       "      <td>01:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.269217</td>\n",
       "      <td>0.270106</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.281358</td>\n",
       "      <td>0.276929</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.263827</td>\n",
       "      <td>0.274039</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.256244</td>\n",
       "      <td>0.264175</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.244181</td>\n",
       "      <td>0.263550</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.243227</td>\n",
       "      <td>0.262685</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.244305</td>\n",
       "      <td>0.257324</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.239147</td>\n",
       "      <td>0.266522</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.248558</td>\n",
       "      <td>0.253301</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.232539</td>\n",
       "      <td>0.258423</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.234523</td>\n",
       "      <td>0.247264</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.224834</td>\n",
       "      <td>0.237199</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.222746</td>\n",
       "      <td>0.242801</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.215752</td>\n",
       "      <td>0.245439</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.208536</td>\n",
       "      <td>0.229339</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>0.236645</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.211470</td>\n",
       "      <td>0.226975</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.203051</td>\n",
       "      <td>0.225054</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.200853</td>\n",
       "      <td>0.221581</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.212063</td>\n",
       "      <td>0.239507</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.200123</td>\n",
       "      <td>0.220029</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.189155</td>\n",
       "      <td>0.215909</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.188677</td>\n",
       "      <td>0.217354</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.187023</td>\n",
       "      <td>0.216025</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.186339</td>\n",
       "      <td>0.221312</td>\n",
       "      <td>01:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.180558</td>\n",
       "      <td>0.209457</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.179857</td>\n",
       "      <td>0.235549</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.177110</td>\n",
       "      <td>0.216069</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.173820</td>\n",
       "      <td>0.218771</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.168724</td>\n",
       "      <td>0.203444</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.165053</td>\n",
       "      <td>0.201878</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.165035</td>\n",
       "      <td>0.198727</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.161363</td>\n",
       "      <td>0.198331</td>\n",
       "      <td>01:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.159578</td>\n",
       "      <td>0.197921</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.157052</td>\n",
       "      <td>0.196784</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.153770</td>\n",
       "      <td>0.192346</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.152212</td>\n",
       "      <td>0.192164</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.149952</td>\n",
       "      <td>0.190279</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.191318</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.147137</td>\n",
       "      <td>0.191029</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.145380</td>\n",
       "      <td>0.188569</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.142669</td>\n",
       "      <td>0.188516</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.139219</td>\n",
       "      <td>0.186768</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.139599</td>\n",
       "      <td>0.187577</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.136724</td>\n",
       "      <td>0.186819</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.135474</td>\n",
       "      <td>0.185001</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.135145</td>\n",
       "      <td>0.184213</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.132261</td>\n",
       "      <td>0.182966</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.130727</td>\n",
       "      <td>0.183530</td>\n",
       "      <td>01:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.130632</td>\n",
       "      <td>0.182399</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.129816</td>\n",
       "      <td>0.183292</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.126376</td>\n",
       "      <td>0.182068</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.126062</td>\n",
       "      <td>0.181194</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.124683</td>\n",
       "      <td>0.180990</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.124794</td>\n",
       "      <td>0.180710</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.122646</td>\n",
       "      <td>0.180506</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.122042</td>\n",
       "      <td>0.180066</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.122910</td>\n",
       "      <td>0.179955</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.121204</td>\n",
       "      <td>0.179547</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.121207</td>\n",
       "      <td>0.179697</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.119713</td>\n",
       "      <td>0.179681</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.119851</td>\n",
       "      <td>0.179474</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.118153</td>\n",
       "      <td>0.179357</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.120237</td>\n",
       "      <td>0.179426</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.119985</td>\n",
       "      <td>0.179331</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.119446</td>\n",
       "      <td>0.179321</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.119122</td>\n",
       "      <td>0.179309</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.117214</td>\n",
       "      <td>0.179309</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: reducing lr to 0.00012196898856054322\n",
      "Epoch 29: reducing lr to 0.00019781622388674128\n",
      "Epoch 39: reducing lr to 0.00018090596753759738\n",
      "Epoch 49: reducing lr to 0.00015000651348627807\n",
      "Epoch 59: reducing lr to 0.00011046063150918881\n",
      "Epoch 69: reducing lr to 6.910620955419162e-05\n",
      "Epoch 79: reducing lr to 3.3093767598933495e-05\n",
      "Epoch 89: reducing lr to 8.650184982654887e-06\n",
      "Epoch 99: reducing lr to 2.0002413089574567e-09\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataLoads = dataLoads_build(x_train, y_train, x_valid, y_valid, batch_size_first)\n",
    "learn = Learner(dataLoads, model, loss_func=L1LossFlat())\n",
    "learn.lr_find()\n",
    "learn.fit_one_cycle(epoch_num_first, lr_max=2e-3, cbs=ReduceLROnPlateau(monitor='valid_loss', min_delta=0.5, patience=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1920c1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of net_test(\n",
       "  (hw_layer): hw_layer(\n",
       "    (evaluate_list): ModuleList(\n",
       "      (0): Embedding(3, 1)\n",
       "      (1): Embedding(3, 1)\n",
       "      (2): Embedding(127, 1)\n",
       "      (3): Embedding(99, 1)\n",
       "      (4): Embedding(2, 1)\n",
       "    )\n",
       "    (focus_list): ModuleList(\n",
       "      (0): Embedding(3, 1)\n",
       "      (1): Embedding(3, 1)\n",
       "      (2): Embedding(127, 1)\n",
       "      (3): Embedding(99, 1)\n",
       "      (4): Embedding(2, 1)\n",
       "    )\n",
       "  )\n",
       "  (embedding): Linear(in_features=234, out_features=128, bias=True)\n",
       "  (lstm1): LSTM(128, 128, bias=False, batch_first=True, bidirectional=True)\n",
       "  (lstm2): LSTM(384, 128, bias=False, batch_first=True, bidirectional=True)\n",
       "  (lstm3): LSTM(640, 128, bias=False, batch_first=True, bidirectional=True)\n",
       "  (lstm4): LSTM(896, 128, bias=False, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=32, bias=False)\n",
       "  (selu): SELU()\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7480b142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-30T16:36:30.336588Z",
     "iopub.status.busy": "2021-10-30T16:36:30.336588Z",
     "iopub.status.idle": "2021-10-30T16:50:59.725400Z",
     "shell.execute_reply": "2021-10-30T16:50:59.725400Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='151' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/151 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 350.00 MiB (GPU 0; 4.00 GiB total capacity; 1.94 GiB already allocated; 23.78 MiB free; 2.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14360/3667361331.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdataLoads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataLoads_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size_second\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlearn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLearner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataLoads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mL1LossFlat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m learn.fit_one_cycle(epoch_num_second, lr_max=2e-3, cbs=[ReduceLROnPlateau(monitor='valid_loss', min_delta=0.5, patience=10),\n\u001b[0;32m      5\u001b[0m                                                         SaveModelCallback(monitor='valid_loss', fname=f'{fname}_best')])\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fastai\\callback\\schedule.py\u001b[0m in \u001b[0;36mlr_find\u001b[1;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[0mn_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[0mcb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLRFinder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstop_div\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_logging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msuggest_funcs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mlrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[1;34m(self, i, b)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'batch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_pred'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14360/501151111.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mx3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\ffly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    692\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    693\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 350.00 MiB (GPU 0; 4.00 GiB total capacity; 1.94 GiB already allocated; 23.78 MiB free; 2.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "dataLoads = dataLoads_build(x_train, y_train, x_valid, y_valid, batch_size_second)\n",
    "learn = Learner(dataLoads, model, loss_func=L1LossFlat())\n",
    "learn.lr_find()\n",
    "learn.fit_one_cycle(epoch_num_second, lr_max=2e-3, cbs=[ReduceLROnPlateau(monitor='valid_loss', min_delta=0.5, patience=10),\n",
    "                                                        SaveModelCallback(monitor='valid_loss', fname=f'{fname}_best')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d169a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from HW_torch import torch_valid, torch_predict\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "state_dict = torch.load(f'models/{fname}_best.pth')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "loss = torch_valid([model.to(device)], L1LossFlat(), (x_train, y_train),  batch_size_second, to_device=device)\n",
    "valid_loss = torch_valid([model.to(device)], L1LossFlat(), (x_valid, y_valid),  batch_size_second, to_device=device)\n",
    "\n",
    "print(loss, valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = torch_predict([model.to(device)], x_test, batch_size_second, to_device=device)\n",
    "predict = np.reshape(predict, (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Database/sample_submission.csv', index_col=0)\n",
    "df['pressure'] = predict\n",
    "\n",
    "df.to_csv(f'Submission/{fname}.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9cf96c7db471cf61b133b0e4e3b2523172ebb61bf8cc081d235291383382076"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
